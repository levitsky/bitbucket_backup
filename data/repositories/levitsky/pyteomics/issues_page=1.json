{"pagelen": 100, "values": [{"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/1/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/1.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/1/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/1/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/1/missing-iter_spectrum-function"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/1/vote"}}, "reporter": null, "title": "Missing iter_spectrum function...", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Upgraded to 2.0 recently and my old script is now broken.  \r\n\r\nRunning the following produces an Attribute error\r\n\r\nspectra = [s for s in mgf.iter_spectrum(mgfFile)]\r\n\r\nAttributeError: 'module' object has no attribute 'iter_spectrum'\r\n\r\nIs there a new syntax that needs to be used?", "markup": "markdown", "html": "<p>Upgraded to 2.0 recently and my old script is now broken.  </p>\n<p>Running the following produces an Attribute error</p>\n<p>spectra = [s for s in mgf.iter_spectrum(mgfFile)]</p>\n<p>AttributeError: 'module' object has no attribute 'iter_spectrum'</p>\n<p>Is there a new syntax that needs to be used?</p>", "type": "rendered"}, "assignee": null, "state": "invalid", "version": null, "edited_on": null, "created_on": "2012-10-10T19:45:26.132646+00:00", "milestone": null, "updated_on": "2013-03-01T21:10:08.327181+00:00", "type": "issue", "id": 1}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/2/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/2.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/2/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/2/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/2/compositions-from-modx-bug"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/2/vote"}}, "reporter": null, "title": "Compositions from modX Bug", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Could not create a Composition object from `seMHHHHHHseMDEYSPKRHDIAQLKFLCETLYHDCLANLEESNHGWVNDPTSAINLQLNELIEHIATFALNYKIKYNEDNKLIEQIDEYLDDTFseMLFSSYGINseMQDLQKWRKSGNRLFRCFVNATKENPASLSC`. A Composition object must be specified by a sequence, parsed sequence, formula or a dict'\r\n\r\nI think having a modified residue in the [0] position interferes with it being recognised as a peptide sequence.", "markup": "markdown", "html": "<p>Could not create a Composition object from <code>seMHHHHHHseMDEYSPKRHDIAQLKFLCETLYHDCLANLEESNHGWVNDPTSAINLQLNELIEHIATFALNYKIKYNEDNKLIEQIDEYLDDTFseMLFSSYGINseMQDLQKWRKSGNRLFRCFVNATKENPASLSC</code>. A Composition object must be specified by a sequence, parsed sequence, formula or a dict'</p>\n<p>I think having a modified residue in the [0] position interferes with it being recognised as a peptide sequence.</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2013-04-18T12:13:16.743529+00:00", "milestone": null, "updated_on": "2018-02-23T23:27:45.597921+00:00", "type": "issue", "id": 2}, {"priority": "minor", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/3/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/3.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/3/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/3/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/3/ms-ms-data-should-list-charge-state-of"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/3/vote"}}, "reporter": null, "title": "MS/MS Data Should List Charge State of Parent Ion", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Using pyteomics 2.1.5\r\n\r\nUsing mzml.read() the returned dictionary per scan does not list the identified charge state of the parent ion, despite the field being listed in a .mzml file (as converted by ProteoWizard).  This information is helpful when interrogating a MS/MS scan to confirm that the right ion was fragmented.", "markup": "markdown", "html": "<p>Using pyteomics 2.1.5</p>\n<p>Using mzml.read() the returned dictionary per scan does not list the identified charge state of the parent ion, despite the field being listed in a .mzml file (as converted by ProteoWizard).  This information is helpful when interrogating a MS/MS scan to confirm that the right ion was fragmented.</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "invalid", "version": null, "edited_on": null, "created_on": "2013-06-01T04:11:32.753864+00:00", "milestone": null, "updated_on": "2014-10-17T15:45:22.960863+00:00", "type": "issue", "id": 3}, {"priority": "minor", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/4/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/4.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/4/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/4/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/4/parser-should-have-way-to-calculate"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/4/vote"}}, "reporter": null, "title": "Parser should have way to calculate elemental composition", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Parser has method to return the amino_acid_composition, returning the elemental composition (ie number of C, H, O, atoms etc) would be helpful.  \r\n\r\nWhen working with modified peptides, this allows easy confirmation of the mass and generation of the theoretical isotopic distribution.", "markup": "markdown", "html": "<p>Parser has method to return the amino_acid_composition, returning the elemental composition (ie number of C, H, O, atoms etc) would be helpful.  </p>\n<p>When working with modified peptides, this allows easy confirmation of the mass and generation of the theoretical isotopic distribution.</p>", "type": "rendered"}, "assignee": null, "state": "on hold", "version": null, "edited_on": null, "created_on": "2013-06-01T04:19:05.711897+00:00", "milestone": null, "updated_on": "2013-06-17T17:02:53.290778+00:00", "type": "issue", "id": 4}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/5/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/5.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/5/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/5/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/5/crash-of-amdx64-installer"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/5/vote"}}, "reporter": {"display_name": "Achim Treumann", "uuid": "{fe720f14-c6f4-4796-90b1-bb204bcaa725}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bfe720f14-c6f4-4796-90b1-bb204bcaa725%7D"}, "html": {"href": "https://bitbucket.org/%7Bfe720f14-c6f4-4796-90b1-bb204bcaa725%7D/"}, "avatar": {"href": "https://bitbucket.org/account/achimt/avatar/"}}, "nickname": "achimt", "type": "user", "account_id": null}, "title": "crash of AMDx64 installer", "component": null, "votes": 0, "watches": 2, "content": {"raw": "Hi Lev and Anton, \r\n\r\ntrying to install pyteomics using \r\npyteomics-2.1.6.win-amd64_py2.7.exe\r\n\r\nThe Installer is crashing on me. I attach a few files that might help diagnosing what's wrong. \r\n\r\nAchim\r\n", "markup": "markdown", "html": "<p>Hi Lev and Anton, </p>\n<p>trying to install pyteomics using \npyteomics-2.1.6.win-amd64_py2.7.exe</p>\n<p>The Installer is crashing on me. I attach a few files that might help diagnosing what's wrong. </p>\n<p>Achim</p>", "type": "rendered"}, "assignee": null, "state": "on hold", "version": null, "edited_on": null, "created_on": "2013-09-12T13:05:51.557667+00:00", "milestone": null, "updated_on": "2013-12-17T12:51:33.219430+00:00", "type": "issue", "id": 5}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/6/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/6.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/6/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/6/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/6/alternative-proteins-not-reported-in"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/6/vote"}}, "reporter": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "title": "Alternative proteins not reported in pyteomics.tandem", "component": null, "votes": 0, "watches": 1, "content": {"raw": "When an X!Tandem XML file is read with `tandem.read()`, and an entry has several `<protein>` elements, only the last one is shown in the output.", "markup": "markdown", "html": "<p>When an X!Tandem XML file is read with <code>tandem.read()</code>, and an entry has several <code>&lt;protein&gt;</code> elements, only the last one is shown in the output.</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2013-12-17T12:07:25.232601+00:00", "milestone": null, "updated_on": "2013-12-20T20:21:06.423734+00:00", "type": "issue", "id": 6}, {"priority": "blocker", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/7/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/7.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/7/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/7/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/7/valueerror-in-pepxmlpy"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/7/vote"}}, "reporter": {"display_name": "Brian Mitchell", "uuid": "{25e274b5-bce3-4833-8d75-fa45f30d294c}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B25e274b5-bce3-4833-8d75-fa45f30d294c%7D"}, "html": {"href": "https://bitbucket.org/%7B25e274b5-bce3-4833-8d75-fa45f30d294c%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a0a7a43d9937b1f5a67e1fe737d21b82d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsBM-1.png"}}, "nickname": "bamitchell54", "type": "user", "account_id": "557058:e7383273-797d-4428-b366-c5bf02d7974e"}, "title": "ValueError in pepxml.py", "component": null, "votes": 0, "watches": 3, "content": {"raw": "I'm running Ubuntu 12.04 through a Virtual Box VM and noticed that when trying to run the example use of `pepxml.read()` shown here (http://pythonhosted.org/pyteomics/data.html), the following error resulted:\r\n\r\n\r\n```\r\n#!python\r\n\r\nFile \"/usr/local/lib/python2.7/dist-packages/pyteomics/pepxml.py\", line 90, in _get_info_smart\r\n    scores[name] = float(value)\r\nValueError: could not convert string to float: Normal\r\n```\r\n\r\n\r\nIt seems that value was a string and using the following change the problem resolved:\r\n\r\n\r\n```\r\n#!python\r\n\r\ntry:\r\n    scores[name] = float(value)\r\nexcept ValueError:\r\n    scores[name] = \"ValueError!\"\r\n```\r\n\r\n\r\nI've attached the pep.xml file used.  Let me know if you guys are aware of this, whether or not it is a bug, and if you need any more information from me.\r\n\r\nBrian", "markup": "markdown", "html": "<p>I'm running Ubuntu 12.04 through a Virtual Box VM and noticed that when trying to run the example use of <code>pepxml.read()</code> shown here (<a href=\"http://pythonhosted.org/pyteomics/data.html\" rel=\"nofollow\" class=\"ap-connect-link\">http://pythonhosted.org/pyteomics/data.html</a>), the following error resulted:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">File</span> <span class=\"s2\">&quot;/usr/local/lib/python2.7/dist-packages/pyteomics/pepxml.py&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">90</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">_get_info_smart</span>\n    <span class=\"n\">scores</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span>\n<span class=\"ne\">ValueError</span><span class=\"p\">:</span> <span class=\"n\">could</span> <span class=\"ow\">not</span> <span class=\"n\">convert</span> <span class=\"n\">string</span> <span class=\"n\">to</span> <span class=\"nb\">float</span><span class=\"p\">:</span> <span class=\"n\">Normal</span>\n</pre></div>\n\n\n<p>It seems that value was a string and using the following change the problem resolved:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">scores</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">value</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">ValueError</span><span class=\"p\">:</span>\n    <span class=\"n\">scores</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;ValueError!&quot;</span>\n</pre></div>\n\n\n<p>I've attached the pep.xml file used.  Let me know if you guys are aware of this, whether or not it is a bug, and if you need any more information from me.</p>\n<p>Brian</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2014-02-04T21:11:08.070999+00:00", "milestone": null, "updated_on": "2014-02-14T09:22:28.840545+00:00", "type": "issue", "id": 7}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/8/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/8.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/8/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/8/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/8/modx-n-terminal-label-issue"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/8/vote"}}, "reporter": {"display_name": "Sven Degroeve", "uuid": "{53b403c9-dc98-4a17-81b5-16080a97698d}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B53b403c9-dc98-4a17-81b5-16080a97698d%7D"}, "html": {"href": "https://bitbucket.org/%7B53b403c9-dc98-4a17-81b5-16080a97698d%7D/"}, "avatar": {"href": "https://bitbucket.org/account/svendegroeve/avatar/"}}, "nickname": "svendegroeve", "type": "user", "account_id": null}, "title": "modX n-terminal label issue", "component": null, "votes": 0, "watches": 2, "content": {"raw": "Hi,\r\n\r\nThank you for a great and useful lib.\r\n\r\nI'm trying to calculate the mass of the peptide with an n-terminal label (Acetylation)\r\nI set the composition of the modification as follows:\r\n\r\n\r\n```\r\n#!python\r\n\r\ndb = mass.Unimod()\r\naa_comp = dict(mass.std_aa_comp)\r\naa_comp['ace'] = db.by_title('Acetyl')['composition']\r\n```\r\n\r\n\r\nThen I try to calculate the mass:\r\n\r\n```\r\n#!python\r\n\r\nmass.calculate_mass(sequence=\"ace-SAMPLE-OH\",aa_comp=aa_comp)\r\n```\r\n\r\n\r\nBut this gives an error:\r\npyteomics.auxiliary.PyteomicsError: Pyteomics error, message: 'Unknown amino acid in sequence ace-SAMPLE-OH at position 1: ace-SAMPLE-OH'\r\n\r\nHow can I specify the composition of an n-terminal label?\r\n\r\nmany thanks,\r\nSven Degroeve\r\n\r\n\r\nVIB Department of Medical Protein Research, UGent\r\nAlbert Baertsoenkaai 3\r\nB-9000 GENT\r\nBELGIUM\r\n\r\n\r\n", "markup": "markdown", "html": "<p>Hi,</p>\n<p>Thank you for a great and useful lib.</p>\n<p>I'm trying to calculate the mass of the peptide with an n-terminal label (Acetylation)\nI set the composition of the modification as follows:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">Unimod</span><span class=\"p\">()</span>\n<span class=\"n\">aa_comp</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">std_aa_comp</span><span class=\"p\">)</span>\n<span class=\"n\">aa_comp</span><span class=\"p\">[</span><span class=\"s1\">&#39;ace&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">by_title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Acetyl&#39;</span><span class=\"p\">)[</span><span class=\"s1\">&#39;composition&#39;</span><span class=\"p\">]</span>\n</pre></div>\n\n\n<p>Then I try to calculate the mass:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">calculate_mass</span><span class=\"p\">(</span><span class=\"n\">sequence</span><span class=\"o\">=</span><span class=\"s2\">&quot;ace-SAMPLE-OH&quot;</span><span class=\"p\">,</span><span class=\"n\">aa_comp</span><span class=\"o\">=</span><span class=\"n\">aa_comp</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>But this gives an error:\npyteomics.auxiliary.PyteomicsError: Pyteomics error, message: 'Unknown amino acid in sequence ace-SAMPLE-OH at position 1: ace-SAMPLE-OH'</p>\n<p>How can I specify the composition of an n-terminal label?</p>\n<p>many thanks,\nSven Degroeve</p>\n<p>VIB Department of Medical Protein Research, UGent\nAlbert Baertsoenkaai 3\nB-9000 GENT\nBELGIUM</p>", "type": "rendered"}, "assignee": null, "state": "invalid", "version": null, "edited_on": null, "created_on": "2014-03-19T18:11:34.597344+00:00", "milestone": null, "updated_on": "2014-03-19T18:27:50.691045+00:00", "type": "issue", "id": 8}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/9/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/9.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/9/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/9/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/9/calculate-mass-of-h-oh-y-ion"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/9/vote"}}, "reporter": {"display_name": "Sven Degroeve", "uuid": "{53b403c9-dc98-4a17-81b5-16080a97698d}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B53b403c9-dc98-4a17-81b5-16080a97698d%7D"}, "html": {"href": "https://bitbucket.org/%7B53b403c9-dc98-4a17-81b5-16080a97698d%7D/"}, "avatar": {"href": "https://bitbucket.org/account/svendegroeve/avatar/"}}, "nickname": "svendegroeve", "type": "user", "account_id": null}, "title": "calculate mass of H-OH y-ion", "component": null, "votes": 0, "watches": 2, "content": {"raw": "The mass class seems to be confused with this y-ion H-OH:\r\n\r\n\r\n```\r\n#!python\r\n\r\nmass.calculate_mass(\"H-OH\", ion_type='y', charge=1)\r\n```\r\n\r\n\r\nPyteomics error, message: 'Could not create a Composition object from string: \"H-OH\": not a valid sequence or formula'", "markup": "markdown", "html": "<p>The mass class seems to be confused with this y-ion H-OH:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">calculate_mass</span><span class=\"p\">(</span><span class=\"s2\">&quot;H-OH&quot;</span><span class=\"p\">,</span> <span class=\"n\">ion_type</span><span class=\"o\">=</span><span class=\"s1\">&#39;y&#39;</span><span class=\"p\">,</span> <span class=\"n\">charge</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>Pyteomics error, message: 'Could not create a Composition object from string: \"H-OH\": not a valid sequence or formula'</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2014-03-20T13:36:09.550428+00:00", "milestone": null, "updated_on": "2014-04-02T08:43:42.194995+00:00", "type": "issue", "id": 9}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/10/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/10.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/10/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/10/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/10/auxfilter-doesnt-work-with-iterators"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/10/vote"}}, "reporter": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "title": "aux.filter doesn't work with iterators", "component": null, "votes": 0, "watches": 1, "content": {"raw": "The `aux.filter` function is supposed to work with iterators, but it doesn't. Instead it consumes the iterator and then yields 0 results.", "markup": "markdown", "html": "<p>The <code>aux.filter</code> function is supposed to work with iterators, but it doesn't. Instead it consumes the iterator and then yields 0 results.</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2014-09-25T15:37:28.524147+00:00", "milestone": null, "updated_on": "2014-09-26T13:56:58.083305+00:00", "type": "issue", "id": 10}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/11/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/11.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/11/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/11/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/11/waters-mzml-fails-due-to-ambiguity-of"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/11/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "Waters mzml fails due to ambiguity of array type labels", "component": null, "votes": 0, "watches": 2, "content": {"raw": "Hello,\r\n\r\nI'm parsing an MzML file produced by Waters, and they may not be standards-conforming in how they produced their XML, but it suggests something is missing in the mzml module.\r\n\r\nThe array type's encoding type is included in \"name\", but so is the kind of information, e.g. `\"charge array\"` or `\"intensity array\"`. The loop which searches for the name at the end of [MzML._get_info_smart,](#!/levitsky/pyteomics/src/edd65283852f3fb6fe43dc25702cb25983940ec3/pyteomics/mzml.py?at=default&fileviewer=file-view-default#mzml.py-147:151) assumes that the name is in the keys of info itself, when they are actually in list of values in `info['name']`\r\n\r\nAn extended version of the loop below\r\n\r\n```\r\n#!python\r\n\r\nfor k in info:\r\n     if k.endswith(' array') and not info[k]:\r\n     info = {k: array}\r\n         break\r\n     elif isinstance(info[k], list) and k == \"name\":\r\n         knames = info[k]\r\n         found = False\r\n         for val in knames:\r\n             if val.endswith(\" array\"):\r\n                 info = {val: array}\r\n                 found = True\r\n                 break\r\n           if found:\r\n               break\r\nelse:\r\n    info['binary'] = array\r\n```\r\n\r\nhandles this issue.\r\n\r\nThe for loop's `else` clause contained a typo, `info['binary'] == array` which caused the function to error out as 'binary' had just been removed from `info` above. I've attached the adjusted version of the mzml module, which passes all tests. I am not sure if I can share the raw data itself as I do not own it. \r\n\r\nWith this adjustment it parses this new data, and continues to pass the mzml unit test. Alternatively, I can commit this code to my branch and open a pull request.\r\n\r\nThank you\r\n\r\n\r\n ", "markup": "markdown", "html": "<p>Hello,</p>\n<p>I'm parsing an MzML file produced by Waters, and they may not be standards-conforming in how they produced their XML, but it suggests something is missing in the mzml module.</p>\n<p>The array type's encoding type is included in \"name\", but so is the kind of information, e.g. <code>\"charge array\"</code> or <code>\"intensity array\"</code>. The loop which searches for the name at the end of <a data-is-external-link=\"true\" href=\"#!/levitsky/pyteomics/src/edd65283852f3fb6fe43dc25702cb25983940ec3/pyteomics/mzml.py?at=default&amp;fileviewer=file-view-default#mzml.py-147:151\" rel=\"nofollow\">MzML._get_info_smart,</a> assumes that the name is in the keys of info itself, when they are actually in list of values in <code>info['name']</code></p>\n<p>An extended version of the loop below</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">for</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">info</span><span class=\"p\">:</span>\n     <span class=\"k\">if</span> <span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">endswith</span><span class=\"p\">(</span><span class=\"s1\">&#39; array&#39;</span><span class=\"p\">)</span> <span class=\"ow\">and</span> <span class=\"ow\">not</span> <span class=\"n\">info</span><span class=\"p\">[</span><span class=\"n\">k</span><span class=\"p\">]:</span>\n     <span class=\"n\">info</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">k</span><span class=\"p\">:</span> <span class=\"n\">array</span><span class=\"p\">}</span>\n         <span class=\"k\">break</span>\n     <span class=\"k\">elif</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">[</span><span class=\"n\">k</span><span class=\"p\">],</span> <span class=\"nb\">list</span><span class=\"p\">)</span> <span class=\"ow\">and</span> <span class=\"n\">k</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;name&quot;</span><span class=\"p\">:</span>\n         <span class=\"n\">knames</span> <span class=\"o\">=</span> <span class=\"n\">info</span><span class=\"p\">[</span><span class=\"n\">k</span><span class=\"p\">]</span>\n         <span class=\"n\">found</span> <span class=\"o\">=</span> <span class=\"bp\">False</span>\n         <span class=\"k\">for</span> <span class=\"n\">val</span> <span class=\"ow\">in</span> <span class=\"n\">knames</span><span class=\"p\">:</span>\n             <span class=\"k\">if</span> <span class=\"n\">val</span><span class=\"o\">.</span><span class=\"n\">endswith</span><span class=\"p\">(</span><span class=\"s2\">&quot; array&quot;</span><span class=\"p\">):</span>\n                 <span class=\"n\">info</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">val</span><span class=\"p\">:</span> <span class=\"n\">array</span><span class=\"p\">}</span>\n                 <span class=\"n\">found</span> <span class=\"o\">=</span> <span class=\"bp\">True</span>\n                 <span class=\"k\">break</span>\n           <span class=\"k\">if</span> <span class=\"n\">found</span><span class=\"p\">:</span>\n               <span class=\"k\">break</span>\n<span class=\"k\">else</span><span class=\"p\">:</span>\n    <span class=\"n\">info</span><span class=\"p\">[</span><span class=\"s1\">&#39;binary&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">array</span>\n</pre></div>\n\n\n<p>handles this issue.</p>\n<p>The for loop's <code>else</code> clause contained a typo, <code>info['binary'] == array</code> which caused the function to error out as 'binary' had just been removed from <code>info</code> above. I've attached the adjusted version of the mzml module, which passes all tests. I am not sure if I can share the raw data itself as I do not own it. </p>\n<p>With this adjustment it parses this new data, and continues to pass the mzml unit test. Alternatively, I can commit this code to my branch and open a pull request.</p>\n<p>Thank you</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2015-10-20T17:36:43.061953+00:00", "milestone": null, "updated_on": "2015-10-25T22:01:22.995333+00:00", "type": "issue", "id": 11}, {"priority": "minor", "kind": "proposal", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/12/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/12.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/12/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/12/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/12/unimod-alternative-names-missing"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/12/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "Unimod Alternative Names Missing", "component": null, "votes": 0, "watches": 2, "content": {"raw": "I'm opening this issue to start a discussion about how to interface with Unimod.\r\n\r\nThere is a disconnect between the logical structure XML and the relational structure XML that Unimod publishes. The logical structure is missing the notion of \"alternative names\", which are present in the relational structure.\r\n\r\nI ran into an issue processing a large mzIdentML file using only the names provided in the logical structure, where for instance the name \"GlyGly\" was used, to refer to \"ubiquitination residue\", and croaked. After some digging I decided to extract the complete object hierarchy from the relational structure.\r\n\r\nOnce the data is loaded, the user creates an instance of the `Unimod` type which they can query using normal `__getitem__` syntax or by using the `get` method (which `__getitem__` is an alias of) with either a number which will be treated as the Unimod accession number, or a string which is will be matched against any name. The Unimod object wraps a SQLAlchemy session, which can be accessed directly under `.session` and queried using the ORM or Core SQL layer from there.\r\n\r\nSince I started with a relational point of view, I wrote my prototype with SQLAlchemy, which could either backend off disk or memory with SQLite3 in the standard library. If the interface I present is acceptable but the use of SQLAlchemy is a blocking issue, I can rewrite the hierarchy to manually track relationships.\r\n\r\nNaturally, a variation on the Unimod constructor would be desirable such that if passed no datastore path, it would fetch down the XML source and build a database in memory.", "markup": "markdown", "html": "<p>I'm opening this issue to start a discussion about how to interface with Unimod.</p>\n<p>There is a disconnect between the logical structure XML and the relational structure XML that Unimod publishes. The logical structure is missing the notion of \"alternative names\", which are present in the relational structure.</p>\n<p>I ran into an issue processing a large mzIdentML file using only the names provided in the logical structure, where for instance the name \"GlyGly\" was used, to refer to \"ubiquitination residue\", and croaked. After some digging I decided to extract the complete object hierarchy from the relational structure.</p>\n<p>Once the data is loaded, the user creates an instance of the <code>Unimod</code> type which they can query using normal <code>__getitem__</code> syntax or by using the <code>get</code> method (which <code>__getitem__</code> is an alias of) with either a number which will be treated as the Unimod accession number, or a string which is will be matched against any name. The Unimod object wraps a SQLAlchemy session, which can be accessed directly under <code>.session</code> and queried using the ORM or Core SQL layer from there.</p>\n<p>Since I started with a relational point of view, I wrote my prototype with SQLAlchemy, which could either backend off disk or memory with SQLite3 in the standard library. If the interface I present is acceptable but the use of SQLAlchemy is a blocking issue, I can rewrite the hierarchy to manually track relationships.</p>\n<p>Naturally, a variation on the Unimod constructor would be desirable such that if passed no datastore path, it would fetch down the XML source and build a database in memory.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2015-10-30T05:21:09.023429+00:00", "milestone": null, "updated_on": "2016-03-01T18:05:50.745869+00:00", "type": "issue", "id": 12}, {"priority": "minor", "kind": "proposal", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/13/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/13.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/13/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/13/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/13/mgf-writing-flag-for-testing-for-existing"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/13/vote"}}, "reporter": {"display_name": "tkschmidt", "uuid": "{ff08b4c9-7da3-4e7d-97a0-5c10cb86ff32}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bff08b4c9-7da3-4e7d-97a0-5c10cb86ff32%7D"}, "html": {"href": "https://bitbucket.org/%7Bff08b4c9-7da3-4e7d-97a0-5c10cb86ff32%7D/"}, "avatar": {"href": "https://bitbucket.org/account/tkschmidt/avatar/"}}, "nickname": "tkschmidt", "type": "user", "account_id": null}, "title": "MGF writing flag for testing for existing file", "component": null, "votes": 0, "watches": 1, "content": {"raw": "\r\nI would like to propose adding an additional optional flag to test whether an MGF with same name exists or a switch to choose between appending or writing.\r\n\r\nAt the moment I always wrap my mgf write functions with a function checking if the file exists. \r\n\r\nTobias\r\n\r\np.s. thanks for your work", "markup": "markdown", "html": "<p>I would like to propose adding an additional optional flag to test whether an MGF with same name exists or a switch to choose between appending or writing.</p>\n<p>At the moment I always wrap my mgf write functions with a function checking if the file exists. </p>\n<p>Tobias</p>\n<p>p.s. thanks for your work</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2015-12-04T12:19:44.922320+00:00", "milestone": null, "updated_on": "2016-01-22T16:08:52.512198+00:00", "type": "issue", "id": 13}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/14/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/14.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/14/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/14/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/14/bug-in-parsing-of-featurexml-files"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/14/vote"}}, "reporter": null, "title": "Bug in parsing of featureXML files", "component": null, "votes": 0, "watches": null, "content": {"raw": "According to schema feature element can have several UserParam child elements. The current implementation of parser returns only the last UserParam, probably since it overwrites them iteratively during parsing. The proper way would be to accumulate all UserParams in the list or in a dictionary with *name* attribute of UserParam element used as a key.\r\nI have attached a simple example.", "markup": "markdown", "html": "<p>According to schema feature element can have several UserParam child elements. The current implementation of parser returns only the last UserParam, probably since it overwrites them iteratively during parsing. The proper way would be to accumulate all UserParams in the list or in a dictionary with <em>name</em> attribute of UserParam element used as a key.\nI have attached a simple example.</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2016-11-15T16:36:47.705107+00:00", "milestone": null, "updated_on": "2016-11-16T13:26:14.521153+00:00", "type": "issue", "id": 14}, {"priority": "major", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/15/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/15.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/15/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/15/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/15/cvparam-unit-awareness"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/15/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "cvParam Unit Awareness", "component": null, "votes": 0, "watches": 1, "content": {"raw": "The current logic for handling cvParam tags in PSIMS standard XML documents discards unit information. \r\n\r\n```python\r\n    def _handle_param(self, element, **kwargs):\r\n        \"\"\"Unpacks cvParam and userParam tags into key-value pairs\"\"\"\r\n        types = {'int': int, 'float': float, 'string': str}\r\n        if 'value' in element.attrib:\r\n            try:\r\n                if element.attrib.get('type') in types:\r\n                    value = types[element.attrib['type']](element.attrib['value'])\r\n                else:\r\n                    value = float(element.attrib['value'])\r\n            except ValueError:\r\n                value = element.attrib['value']\r\n            return {element.attrib['name']: value}\r\n        else:\r\n            return {'name': element.attrib['name']}\r\n```\r\n\r\nHere, if a unit were present, there would be attributes such as unitCVRef, unitAccession, and unitName. The first two attributes together can be used to resolve the definition of the unit from a controlled vocabulary, while the third gives a common name for the unit, which is usually enough context for a program to make the correct decision. Since this value is discarded before it reaches the caller, that is impossible. For example, some time-related fields are recorded in minutes while others are in seconds.\r\n\r\nI propose three solutions for consideration:\r\n\r\n1. Create a new \"Parameter\" type which wraps all of the information contained in the cvParam tag, and force all callers to unwrap the object to access the primitive value therein. This breaks all client code but is more future-proof and provides more semantic information.\r\n2. Create a set of data type specific wrappers for `float`, `int`, and `str` that inherit from the matching builtin type, which has a spot for storing the unit (and other metadata?). This doesn't break client code, but it may mean that unit information is lost when passed through conversion operations.\r\n3. Rather than create our own wrappers, use a library like [units](https://pypi.python.org/pypi/units) or [pint](https://github.com/hgrecco/pint) to provide this behavior. These types have been through more testing, but also support dimensionality checking so that you can operate on quantities of the same dimension or dimensionless quantities, but institutes error checking when operating on non-conforming dimensions together. This is hard to predict how it will break client code.\r\n\r\nI'm partial to option 2 since 1 involves a lot of rewriting of code that doesn't really care about units, and option 3 is hard to analyze and adds a new dependency that can break in unpredictable ways.\r\n\r\nI'm planning to start work on this issue in a few days, but I wanted to get the options reviewed before I started.", "markup": "markdown", "html": "<p>The current logic for handling cvParam tags in PSIMS standard XML documents discards unit information. </p>\n<div class=\"codehilite language-python\"><pre><span></span>    <span class=\"k\">def</span> <span class=\"nf\">_handle_param</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">element</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"sd\">&quot;&quot;&quot;Unpacks cvParam and userParam tags into key-value pairs&quot;&quot;&quot;</span>\n        <span class=\"n\">types</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">&#39;int&#39;</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"s1\">&#39;float&#39;</span><span class=\"p\">:</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"s1\">&#39;string&#39;</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">}</span>\n        <span class=\"k\">if</span> <span class=\"s1\">&#39;value&#39;</span> <span class=\"ow\">in</span> <span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">:</span>\n            <span class=\"k\">try</span><span class=\"p\">:</span>\n                <span class=\"k\">if</span> <span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">&#39;type&#39;</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"n\">types</span><span class=\"p\">:</span>\n                    <span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"n\">types</span><span class=\"p\">[</span><span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">&#39;type&#39;</span><span class=\"p\">]](</span><span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">&#39;value&#39;</span><span class=\"p\">])</span>\n                <span class=\"k\">else</span><span class=\"p\">:</span>\n                    <span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">&#39;value&#39;</span><span class=\"p\">])</span>\n            <span class=\"k\">except</span> <span class=\"ne\">ValueError</span><span class=\"p\">:</span>\n                <span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">&#39;value&#39;</span><span class=\"p\">]</span>\n            <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">&#39;name&#39;</span><span class=\"p\">]:</span> <span class=\"n\">value</span><span class=\"p\">}</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s1\">&#39;name&#39;</span><span class=\"p\">:</span> <span class=\"n\">element</span><span class=\"o\">.</span><span class=\"n\">attrib</span><span class=\"p\">[</span><span class=\"s1\">&#39;name&#39;</span><span class=\"p\">]}</span>\n</pre></div>\n\n\n<p>Here, if a unit were present, there would be attributes such as unitCVRef, unitAccession, and unitName. The first two attributes together can be used to resolve the definition of the unit from a controlled vocabulary, while the third gives a common name for the unit, which is usually enough context for a program to make the correct decision. Since this value is discarded before it reaches the caller, that is impossible. For example, some time-related fields are recorded in minutes while others are in seconds.</p>\n<p>I propose three solutions for consideration:</p>\n<ol>\n<li>Create a new \"Parameter\" type which wraps all of the information contained in the cvParam tag, and force all callers to unwrap the object to access the primitive value therein. This breaks all client code but is more future-proof and provides more semantic information.</li>\n<li>Create a set of data type specific wrappers for <code>float</code>, <code>int</code>, and <code>str</code> that inherit from the matching builtin type, which has a spot for storing the unit (and other metadata?). This doesn't break client code, but it may mean that unit information is lost when passed through conversion operations.</li>\n<li>Rather than create our own wrappers, use a library like <a data-is-external-link=\"true\" href=\"https://pypi.python.org/pypi/units\" rel=\"nofollow\">units</a> or <a data-is-external-link=\"true\" href=\"https://github.com/hgrecco/pint\" rel=\"nofollow\">pint</a> to provide this behavior. These types have been through more testing, but also support dimensionality checking so that you can operate on quantities of the same dimension or dimensionless quantities, but institutes error checking when operating on non-conforming dimensions together. This is hard to predict how it will break client code.</li>\n</ol>\n<p>I'm partial to option 2 since 1 involves a lot of rewriting of code that doesn't really care about units, and option 3 is hard to analyze and adds a new dependency that can break in unpredictable ways.</p>\n<p>I'm planning to start work on this issue in a few days, but I wanted to get the options reviewed before I started.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2017-01-03T23:47:45.453066+00:00", "milestone": null, "updated_on": "2017-01-12T13:08:56.100442+00:00", "type": "issue", "id": 15}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/16/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/16.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/16/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/16/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/16/checking-of-string-inclusivity-in"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/16/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "Checking of string inclusivity in _get_info-related dictionaries of formats using base64 encoded data is dangerous", "component": null, "votes": 0, "watches": 1, "content": {"raw": "In the `mzml` module, `_get_info_smart` uses the `in` operator to check to see if a particular string key is in the `info` variable returned by `_get_info`. `_get_info` usually returns a `dict`, except when it encounters a tag whose only purpose is to contain text, in which case it returns the tag's text instead of a `dict`.\r\n\r\nThis is dangerous if the same string may be present either as a key or as the contents of a tag's text. This should be rare since the range of values tested for is small, only \"binary\" and \"binaryDataArray\". Unfortunately, rare events do happen.\r\n\r\nIn this example, one of the base64 encoded blobs in an mzML file contains the sequence \"binary\" in the encoded text:\r\n\r\n\"bQ2vj1EQ8ocJHBNQi6bTsURUFFmReTN2Dct/2cedBZ6aJFKZH+zt6MGlh8VbK/BVK45+57Cze2qPVGoC11SOw3aP/iZ/sKfDfuTE**binary**pfyL0i5o/tsx5AD0n5x9xgeXNfx+HYVshqTiivDO+5se2nBwXbD0DLS73TJtC4smrXgvQvk7pDbBMI6yKCcaCk4YfEyFUf\"\r\n\r\nThe check in the code is:\r\n```python\r\n        if 'binary' in info:\r\n```\r\n\r\nTo make the check handle this scenario:\r\n```python\r\n        if 'binary' in info and isinstance(info, dict):\r\n```\r\n\r\nConceivably, this could happen anywhere we might receive a string instead of a dictionary,  but it's most unpredictable around the base64 blobs.", "markup": "markdown", "html": "<p>In the <code>mzml</code> module, <code>_get_info_smart</code> uses the <code>in</code> operator to check to see if a particular string key is in the <code>info</code> variable returned by <code>_get_info</code>. <code>_get_info</code> usually returns a <code>dict</code>, except when it encounters a tag whose only purpose is to contain text, in which case it returns the tag's text instead of a <code>dict</code>.</p>\n<p>This is dangerous if the same string may be present either as a key or as the contents of a tag's text. This should be rare since the range of values tested for is small, only \"binary\" and \"binaryDataArray\". Unfortunately, rare events do happen.</p>\n<p>In this example, one of the base64 encoded blobs in an mzML file contains the sequence \"binary\" in the encoded text:</p>\n<p>\"bQ2vj1EQ8ocJHBNQi6bTsURUFFmReTN2Dct/2cedBZ6aJFKZH+zt6MGlh8VbK/BVK45+57Cze2qPVGoC11SOw3aP/iZ/sKfDfuTE<strong>binary</strong>pfyL0i5o/tsx5AD0n5x9xgeXNfx+HYVshqTiivDO+5se2nBwXbD0DLS73TJtC4smrXgvQvk7pDbBMI6yKCcaCk4YfEyFUf\"</p>\n<p>The check in the code is:</p>\n<div class=\"codehilite language-python\"><pre><span></span>        <span class=\"k\">if</span> <span class=\"s1\">&#39;binary&#39;</span> <span class=\"ow\">in</span> <span class=\"n\">info</span><span class=\"p\">:</span>\n</pre></div>\n\n\n<p>To make the check handle this scenario:</p>\n<div class=\"codehilite language-python\"><pre><span></span>        <span class=\"k\">if</span> <span class=\"s1\">&#39;binary&#39;</span> <span class=\"ow\">in</span> <span class=\"n\">info</span> <span class=\"ow\">and</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">,</span> <span class=\"nb\">dict</span><span class=\"p\">):</span>\n</pre></div>\n\n\n<p>Conceivably, this could happen anywhere we might receive a string instead of a dictionary,  but it's most unpredictable around the base64 blobs.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2017-01-12T16:39:03.744140+00:00", "milestone": null, "updated_on": "2017-01-12T22:37:49.213548+00:00", "type": "issue", "id": 16}, {"priority": "minor", "kind": "proposal", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/17/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/17.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/17/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/17/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/17/pre-indexing-xml-files"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/17/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "Pre-indexing XML Files", "component": null, "votes": 0, "watches": 1, "content": {"raw": "When using the IndexedXML-derived parsers, every time a reader is instantiated, the whole file must be read over to build the byte offset index in memory, as we don't try or trust the tail index. On very large files, this scanning process can take between 5 and 20 seconds. This may just be inconvenient at times, but it also means that parallelizing operations must have a much greater work savings in order to be worthwhile. I've implemented a suite of methods to save the byte offset index to a file and query that file before performing the whole file scan.  This means that after pre-indexing the file, new readers are immediately ready to use and do not incur that startup cost. If the index file is missing, it falls back to the normal behavior of scanning the file.\r\n\r\n```python\r\n\r\ndef save_byte_index(index, fp):\r\n    \"\"\"Write the byte offset index to the provided\r\n    file\r\n\r\n    Parameters\r\n    ----------\r\n    index : ByteEncodingOrderedDict\r\n        The byte offset index to be saved\r\n    fp : file\r\n        The file to write the index to\r\n\r\n    Returns\r\n    -------\r\n    file\r\n    \"\"\"\r\n    encoded_index = dict()\r\n    for key, offset in index.items():\r\n        encoded_index[key.decode(\"utf8\")] = offset\r\n    json.dump(encoded_index, fp)\r\n    return fp\r\n\r\n\r\ndef load_byte_index(fp):\r\n    \"\"\"Read a byte offset index from a file\r\n\r\n    Parameters\r\n    ----------\r\n    fp : file\r\n        The file to read the index from\r\n\r\n    Returns\r\n    -------\r\n    ByteEncodingOrderedDict\r\n    \"\"\"\r\n    data = json.load(fp)\r\n    index = xml.ByteEncodingOrderedDict()\r\n    for key, value in sorted(data.items(), key=lambda x: x[1]):\r\n        index[key] = value\r\n    return index\r\n\r\n\r\nclass PrebuiltOffsetIndex(xml.FlatTagSpecificXMLByteIndex):\r\n    \"\"\"An Offset Index class which just holds offsets\r\n    and performs no extra scanning effort.\r\n\r\n    Attributes\r\n    ----------\r\n    offsets : ByteEncodingOrderedDict\r\n    \"\"\"\r\n\r\n    def __init__(self, offsets):\r\n        self.offsets = offsets\r\n\r\n\r\nclass IndexSavingXML(xml.IndexedXML):\r\n    \"\"\"An extension to the IndexedXML type which\r\n    adds facilities to read and write the byte offset\r\n    index externally.\r\n    \"\"\"\r\n\r\n    _save_byte_index_to_file = staticmethod(save_byte_index)\r\n    _load_byte_index_from_file = staticmethod(load_byte_index)\r\n\r\n    @property\r\n    def _byte_offset_filename(self):\r\n        path = self._source.name\r\n        byte_offset_filename = os.path.splitext(path)[0] + '-byte-offsets.json'\r\n        return byte_offset_filename\r\n\r\n    def _check_has_byte_offset_file(self):\r\n        path = self._byte_offset_filename\r\n        return os.path.exists(path)\r\n\r\n    def _read_byte_offsets(self):\r\n        with open(self._byte_offset_filename, 'r') as f:\r\n            index = PrebuiltOffsetIndex(self._load_byte_index_from_file(f))\r\n            self._offset_index = index\r\n\r\n    def _write_byte_offsets(self):\r\n        with open(self._byte_offset_filename, 'w') as f:\r\n            self._save_byte_index_to_file(self._offset_index, f)\r\n\r\n    @xml._keepstate\r\n    def _build_index(self):\r\n        try:\r\n            self._read_byte_offsets()\r\n        except IOError:\r\n            super(IndexSavingXML, self)._build_index()\r\n\r\n    @classmethod\r\n    def prebuild_byte_offset_file(cls, path):\r\n        inst = cls(path, use_index=True)\r\n        inst._write_byte_offsets()\r\n```\r\n\r\nIf you agree this is a good idea, I'll integrate this into my fork and make `MzML` and `MzXML` descend from this class instead of IndexedXML directly.", "markup": "markdown", "html": "<p>When using the IndexedXML-derived parsers, every time a reader is instantiated, the whole file must be read over to build the byte offset index in memory, as we don't try or trust the tail index. On very large files, this scanning process can take between 5 and 20 seconds. This may just be inconvenient at times, but it also means that parallelizing operations must have a much greater work savings in order to be worthwhile. I've implemented a suite of methods to save the byte offset index to a file and query that file before performing the whole file scan.  This means that after pre-indexing the file, new readers are immediately ready to use and do not incur that startup cost. If the index file is missing, it falls back to the normal behavior of scanning the file.</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">save_byte_index</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">fp</span><span class=\"p\">):</span>\n    <span class=\"sd\">&quot;&quot;&quot;Write the byte offset index to the provided</span>\n<span class=\"sd\">    file</span>\n\n<span class=\"sd\">    Parameters</span>\n<span class=\"sd\">    ----------</span>\n<span class=\"sd\">    index : ByteEncodingOrderedDict</span>\n<span class=\"sd\">        The byte offset index to be saved</span>\n<span class=\"sd\">    fp : file</span>\n<span class=\"sd\">        The file to write the index to</span>\n\n<span class=\"sd\">    Returns</span>\n<span class=\"sd\">    -------</span>\n<span class=\"sd\">    file</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n    <span class=\"n\">encoded_index</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">()</span>\n    <span class=\"k\">for</span> <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">offset</span> <span class=\"ow\">in</span> <span class=\"n\">index</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">():</span>\n        <span class=\"n\">encoded_index</span><span class=\"p\">[</span><span class=\"n\">key</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">(</span><span class=\"s2\">&quot;utf8&quot;</span><span class=\"p\">)]</span> <span class=\"o\">=</span> <span class=\"n\">offset</span>\n    <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dump</span><span class=\"p\">(</span><span class=\"n\">encoded_index</span><span class=\"p\">,</span> <span class=\"n\">fp</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">fp</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">load_byte_index</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">):</span>\n    <span class=\"sd\">&quot;&quot;&quot;Read a byte offset index from a file</span>\n\n<span class=\"sd\">    Parameters</span>\n<span class=\"sd\">    ----------</span>\n<span class=\"sd\">    fp : file</span>\n<span class=\"sd\">        The file to read the index from</span>\n\n<span class=\"sd\">    Returns</span>\n<span class=\"sd\">    -------</span>\n<span class=\"sd\">    ByteEncodingOrderedDict</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"p\">)</span>\n    <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">ByteEncodingOrderedDict</span><span class=\"p\">()</span>\n    <span class=\"k\">for</span> <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"ow\">in</span> <span class=\"nb\">sorted</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">(),</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]):</span>\n        <span class=\"n\">index</span><span class=\"p\">[</span><span class=\"n\">key</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">value</span>\n    <span class=\"k\">return</span> <span class=\"n\">index</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">PrebuiltOffsetIndex</span><span class=\"p\">(</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">FlatTagSpecificXMLByteIndex</span><span class=\"p\">):</span>\n    <span class=\"sd\">&quot;&quot;&quot;An Offset Index class which just holds offsets</span>\n<span class=\"sd\">    and performs no extra scanning effort.</span>\n\n<span class=\"sd\">    Attributes</span>\n<span class=\"sd\">    ----------</span>\n<span class=\"sd\">    offsets : ByteEncodingOrderedDict</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">offsets</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">offsets</span> <span class=\"o\">=</span> <span class=\"n\">offsets</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">IndexSavingXML</span><span class=\"p\">(</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">IndexedXML</span><span class=\"p\">):</span>\n    <span class=\"sd\">&quot;&quot;&quot;An extension to the IndexedXML type which</span>\n<span class=\"sd\">    adds facilities to read and write the byte offset</span>\n<span class=\"sd\">    index externally.</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n\n    <span class=\"n\">_save_byte_index_to_file</span> <span class=\"o\">=</span> <span class=\"nb\">staticmethod</span><span class=\"p\">(</span><span class=\"n\">save_byte_index</span><span class=\"p\">)</span>\n    <span class=\"n\">_load_byte_index_from_file</span> <span class=\"o\">=</span> <span class=\"nb\">staticmethod</span><span class=\"p\">(</span><span class=\"n\">load_byte_index</span><span class=\"p\">)</span>\n\n    <span class=\"nd\">@property</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_byte_offset_filename</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_source</span><span class=\"o\">.</span><span class=\"n\">name</span>\n        <span class=\"n\">byte_offset_filename</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">splitext</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"s1\">&#39;-byte-offsets.json&#39;</span>\n        <span class=\"k\">return</span> <span class=\"n\">byte_offset_filename</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_check_has_byte_offset_file</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_byte_offset_filename</span>\n        <span class=\"k\">return</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_read_byte_offsets</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_byte_offset_filename</span><span class=\"p\">,</span> <span class=\"s1\">&#39;r&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">PrebuiltOffsetIndex</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_load_byte_index_from_file</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">))</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_offset_index</span> <span class=\"o\">=</span> <span class=\"n\">index</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_write_byte_offsets</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_byte_offset_filename</span><span class=\"p\">,</span> <span class=\"s1\">&#39;w&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_save_byte_index_to_file</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_offset_index</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"p\">)</span>\n\n    <span class=\"nd\">@xml._keepstate</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_build_index</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">try</span><span class=\"p\">:</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_read_byte_offsets</span><span class=\"p\">()</span>\n        <span class=\"k\">except</span> <span class=\"ne\">IOError</span><span class=\"p\">:</span>\n            <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">IndexSavingXML</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">_build_index</span><span class=\"p\">()</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">prebuild_byte_offset_file</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">path</span><span class=\"p\">):</span>\n        <span class=\"n\">inst</span> <span class=\"o\">=</span> <span class=\"bp\">cls</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">use_index</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n        <span class=\"n\">inst</span><span class=\"o\">.</span><span class=\"n\">_write_byte_offsets</span><span class=\"p\">()</span>\n</pre></div>\n\n\n<p>If you agree this is a good idea, I'll integrate this into my fork and make <code>MzML</code> and <code>MzXML</code> descend from this class instead of IndexedXML directly.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2017-08-22T23:51:12.718655+00:00", "milestone": null, "updated_on": "2017-08-25T22:38:54.943099+00:00", "type": "issue", "id": 17}, {"priority": "minor", "kind": "proposal", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/18/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/18.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/18/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/18/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/18/make-binary-array-decoding-optional"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/18/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "Make binary array decoding optional", "component": null, "votes": 0, "watches": 1, "content": {"raw": "When iterating over an mzML or mzXML file with many big binary arrays, a large portion of time is spent doing binary decoding. For use cases like looping over the file to determine which scans are MS1 vs. MS2, this could cost a substantial amount of time. For my example, I've created a simple subclass which never decodes arrays. \r\n\r\n```python\r\nclass NonDecodingMzML(mzml.MzML):\r\n    def _handle_binary(self, info, **kwargs):\r\n        b = info.pop('binary')\r\n        name = self._detect_array_name(info)\r\n        if name == 'binary':\r\n            info[name] = b\r\n        else:\r\n            info = {name: b}\r\n        return info\r\n```\r\n\r\nTo test the performance numbers, I looped over a large mzML file with both `MzML` and `NonDecodingMzML` with the profiler turned on. Here are the numbers for the decoding `MzML`:\r\n\r\n```\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n    23538   28.378    0.001   28.378    0.001 {binascii.a2b_base64}\r\n    15358   22.254    0.001  111.727    0.007 xml.py:388(iterfind)\r\n    23538   21.668    0.001   21.668    0.001 {method 'encode' of 'str' objects}\r\n198480/15357   16.859    0.000   87.290    0.006 xml.py:311(_get_info)\r\n198480/15357   13.265    0.000   87.480    0.006 mzml.py:232(_get_info_smart)\r\n```\r\n\r\nHere are the numbers for `NonDecodingMzML`:\r\n```\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n    15358   20.799    0.001   58.879    0.004 xml.py:388(iterfind)\r\n198480/15357   16.557    0.000   35.901    0.002 xml.py:311(_get_info)\r\n198480/15357   13.163    0.000   36.087    0.002 mzml.py:232(_get_info_smart)\r\n```\r\n The total time spent in `iterfind` was shrank to 52% of the original time by skipping the decoding step. \r\n\r\nI propose we add a new keyword argument to the constructor of `MzML` and `MzXML` which will be true by default that signals that binary arrays should be decoded, and when false, should be left as bytes (or completely omitted?).  If this change makes sense to you, I'll integrate the change into my fork and open a new pull request", "markup": "markdown", "html": "<p>When iterating over an mzML or mzXML file with many big binary arrays, a large portion of time is spent doing binary decoding. For use cases like looping over the file to determine which scans are MS1 vs. MS2, this could cost a substantial amount of time. For my example, I've created a simple subclass which never decodes arrays. </p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">NonDecodingMzML</span><span class=\"p\">(</span><span class=\"n\">mzml</span><span class=\"o\">.</span><span class=\"n\">MzML</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_handle_binary</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">info</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;binary&#39;</span><span class=\"p\">)</span>\n        <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_detect_array_name</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">name</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;binary&#39;</span><span class=\"p\">:</span>\n            <span class=\"n\">info</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">b</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"n\">info</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"n\">b</span><span class=\"p\">}</span>\n        <span class=\"k\">return</span> <span class=\"n\">info</span>\n</pre></div>\n\n\n<p>To test the performance numbers, I looped over a large mzML file with both <code>MzML</code> and <code>NonDecodingMzML</code> with the profiler turned on. Here are the numbers for the decoding <code>MzML</code>:</p>\n<div class=\"codehilite\"><pre><span></span>   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    23538   28.378    0.001   28.378    0.001 {binascii.a2b_base64}\n    15358   22.254    0.001  111.727    0.007 xml.py:388(iterfind)\n    23538   21.668    0.001   21.668    0.001 {method &#39;encode&#39; of &#39;str&#39; objects}\n198480/15357   16.859    0.000   87.290    0.006 xml.py:311(_get_info)\n198480/15357   13.265    0.000   87.480    0.006 mzml.py:232(_get_info_smart)\n</pre></div>\n\n\n<p>Here are the numbers for <code>NonDecodingMzML</code>:</p>\n<div class=\"codehilite\"><pre><span></span>   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    15358   20.799    0.001   58.879    0.004 xml.py:388(iterfind)\n198480/15357   16.557    0.000   35.901    0.002 xml.py:311(_get_info)\n198480/15357   13.163    0.000   36.087    0.002 mzml.py:232(_get_info_smart)\n</pre></div>\n\n\n<p>The total time spent in <code>iterfind</code> was shrank to 52% of the original time by skipping the decoding step. </p>\n<p>I propose we add a new keyword argument to the constructor of <code>MzML</code> and <code>MzXML</code> which will be true by default that signals that binary arrays should be decoded, and when false, should be left as bytes (or completely omitted?).  If this change makes sense to you, I'll integrate the change into my fork and open a new pull request</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2017-08-23T01:41:22.470764+00:00", "milestone": null, "updated_on": "2017-08-26T14:54:32.647639+00:00", "type": "issue", "id": 18}, {"priority": "minor", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/19/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/19.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/19/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/19/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/19/more-of-a-question-than-issue"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/19/vote"}}, "reporter": {"display_name": "Matteo Lacki", "uuid": "{0aa740a7-9fa8-4a45-ad13-18e05528160e}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B0aa740a7-9fa8-4a45-ad13-18e05528160e%7D"}, "html": {"href": "https://bitbucket.org/%7B0aa740a7-9fa8-4a45-ad13-18e05528160e%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/696a8c1520b815233582aa1bf923a809d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsML-5.png"}}, "nickname": "Mateusz \u0141\u0105cki", "type": "user", "account_id": "557058:aa1b63e0-6c01-4920-aa1a-b9e9368b25b2"}, "title": "More of a question than issue", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Hi,\r\n\r\nFirst of all, this software is great, thanks.\r\nI am using it to access mzXml files, mainly like that:\r\n```\r\n#!python\r\nwith mzxml.read(path) as reader:\r\n    k = 0\r\n    for spectrum in reader:\r\n        mz = spectrum['m/z array']\r\n        intensity = spectrum['intensity array']\r\n    yield mz, intensity\r\n```\r\n\r\nMy question is: do you have a direct generator of (mz,intensity) tuples?\r\nI mean something like that:\r\n\r\n```\r\n#!python\r\nwith mzxml.read(path) as reader:\r\n    k = 0\r\n    for spectrum in reader:\r\n        for mz, intensity in spectrum:\r\n            yield mz, intensity, spectrum.run_numbers\r\n```\r\n\r\nI don't know how your parser works underneath Python,\r\nbut I was wondering if you can save on RAM.\r\n\r\nBest wishes!", "markup": "markdown", "html": "<p>Hi,</p>\n<p>First of all, this software is great, thanks.\nI am using it to access mzXml files, mainly like that:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">with</span> <span class=\"n\">mzxml</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">reader</span><span class=\"p\">:</span>\n    <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"k\">for</span> <span class=\"n\">spectrum</span> <span class=\"ow\">in</span> <span class=\"n\">reader</span><span class=\"p\">:</span>\n        <span class=\"n\">mz</span> <span class=\"o\">=</span> <span class=\"n\">spectrum</span><span class=\"p\">[</span><span class=\"s1\">&#39;m/z array&#39;</span><span class=\"p\">]</span>\n        <span class=\"n\">intensity</span> <span class=\"o\">=</span> <span class=\"n\">spectrum</span><span class=\"p\">[</span><span class=\"s1\">&#39;intensity array&#39;</span><span class=\"p\">]</span>\n    <span class=\"k\">yield</span> <span class=\"n\">mz</span><span class=\"p\">,</span> <span class=\"n\">intensity</span>\n</pre></div>\n\n\n<p>My question is: do you have a direct generator of (mz,intensity) tuples?\nI mean something like that:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">with</span> <span class=\"n\">mzxml</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">reader</span><span class=\"p\">:</span>\n    <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"k\">for</span> <span class=\"n\">spectrum</span> <span class=\"ow\">in</span> <span class=\"n\">reader</span><span class=\"p\">:</span>\n        <span class=\"k\">for</span> <span class=\"n\">mz</span><span class=\"p\">,</span> <span class=\"n\">intensity</span> <span class=\"ow\">in</span> <span class=\"n\">spectrum</span><span class=\"p\">:</span>\n            <span class=\"k\">yield</span> <span class=\"n\">mz</span><span class=\"p\">,</span> <span class=\"n\">intensity</span><span class=\"p\">,</span> <span class=\"n\">spectrum</span><span class=\"o\">.</span><span class=\"n\">run_numbers</span>\n</pre></div>\n\n\n<p>I don't know how your parser works underneath Python,\nbut I was wondering if you can save on RAM.</p>\n<p>Best wishes!</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2017-11-17T10:40:22.770279+00:00", "milestone": null, "updated_on": "2017-11-19T18:58:06.261569+00:00", "type": "issue", "id": 19}, {"priority": "minor", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/20/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/20.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/20/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/20/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/20/modifying-peptides-with-options-ntermx-and"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/20/vote"}}, "reporter": {"display_name": "Vasyka", "uuid": "{33bae914-39a6-4258-bfb8-03296e4d1413}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B33bae914-39a6-4258-bfb8-03296e4d1413%7D"}, "html": {"href": "https://bitbucket.org/%7B33bae914-39a6-4258-bfb8-03296e4d1413%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/ac876cf21d640e5d8698e18a22a794b1d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsV-3.png"}}, "nickname": "vasyka", "type": "user", "account_id": "5a181770c51854164d650689"}, "title": "Modifying peptides with options \u2018ntermX\u2019 and \u2018ctermY\u2019", "component": null, "votes": 0, "watches": 2, "content": {"raw": "I want to make modifications with the first residue in the peptide. As I understand from documentation, I can do it using function ```parser.isoforms(sequence, **kwargs)``` and setting \u2018ntermX\u2019 value in the argument ```variable mods``` . But when I run this code:\r\n\r\n```\r\n#!python\r\nset(parser.isoforms(\"PEPTIDE\", variable_mods={'[p]': 'ntermX'}))\r\n\r\n```\r\nI get only 'PEPTIDE' in set. So, why it is not working?", "markup": "markdown", "html": "<p>I want to make modifications with the first residue in the peptide. As I understand from documentation, I can do it using function <code>parser.isoforms(sequence, **kwargs)</code> and setting \u2018ntermX\u2019 value in the argument <code>variable mods</code> . But when I run this code:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">isoforms</span><span class=\"p\">(</span><span class=\"s2\">&quot;PEPTIDE&quot;</span><span class=\"p\">,</span> <span class=\"n\">variable_mods</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;[p]&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;ntermX&#39;</span><span class=\"p\">}))</span>\n</pre></div>\n\n\n<p>I get only 'PEPTIDE' in set. So, why it is not working?</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2017-11-24T13:39:11.413377+00:00", "milestone": null, "updated_on": "2017-11-24T14:21:34.795744+00:00", "type": "issue", "id": 20}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/21/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/21.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/21/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/21/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/21/cant-get-the-mzidentml-schema-for-version"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/21/vote"}}, "reporter": null, "title": "Can't get the mzIdentML schema for version", "component": null, "votes": 0, "watches": null, "content": {"raw": "I'm trying to use the mzid function to open MzIdentMl 1.2 files and it says that is not possible to get the schema, and for that reason, the pyton program is unable to select the information that I need.\r\n\r\nIs it pyteomics only suitable for MzIdentMl 1.1 files?", "markup": "markdown", "html": "<p>I'm trying to use the mzid function to open MzIdentMl 1.2 files and it says that is not possible to get the schema, and for that reason, the pyton program is unable to select the information that I need.</p>\n<p>Is it pyteomics only suitable for MzIdentMl 1.1 files?</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-02-05T12:05:18.058301+00:00", "milestone": null, "updated_on": "2018-02-05T21:47:01.646628+00:00", "type": "issue", "id": 21}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/22/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/22.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/22/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/22/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/22/isotopologues-kwargs-errors"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/22/vote"}}, "reporter": {"display_name": "jacobrosenstein", "uuid": "{15b69590-5316-43cf-92b2-426db558db61}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B15b69590-5316-43cf-92b2-426db558db61%7D"}, "html": {"href": "https://bitbucket.org/%7B15b69590-5316-43cf-92b2-426db558db61%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/d3c71a487a958950c1466398730b1f58d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJ-4.png"}}, "nickname": "jacobrosenstein", "type": "user", "account_id": "5a9095b90e69ba52f30623f3"}, "title": "isotopologues kwargs errors", "component": null, "votes": 0, "watches": 1, "content": {"raw": "When I call mass.isotopologues with a 'composition' argument:\r\n\r\n\r\n```\r\n#!python\r\n\r\nmass.isotopologues(composition=composition,\r\n                                               report_abundance=True,\r\n                                               isotope_threshold=isotope_threshold,\r\n                                               overall_threshold=overall_threshold)\r\n```\r\n\r\n\r\n\r\nIt causes an error because it passes 2 'composition' kwargs to another function:\r\n\r\n\r\n```\r\n#!python\r\n\r\n/pyteomics/mass/mass.py\", line 715, in isotopologues\r\n   abundance = isotopic_composition_abundance(composition=ic, **kwargs)\r\nTypeError: isotopic_composition_abundance() got multiple values for keyword argument 'composition'\r\n```\r\n\r\n\r\nA similar error also happened with the 'formula' argument.\r\n\r\nThis may or may not be the best solution, but it can be fixed by removing 'composition' and 'formula' from kwargs before passing to isotopic_composition_abundance:\r\n\r\n```\r\n#!python\r\n\r\n    for isotopologue in product(*all_isotoplogues):\r\n        \r\n        if 'formula' in kwargs:\r\n            kwargs.pop('formula')\r\n\r\n        if 'composition' in kwargs:\r\n            kwargs.pop('composition')\r\n        \r\n        ic = Composition(formula=''.join(atom for el in isotopologue for atom in el), **kwargs)\r\n        if report_abundance or overall_threshold > 0.0:\r\n            abundance = isotopic_composition_abundance(composition=ic, **kwargs)\r\n\r\n```", "markup": "markdown", "html": "<p>When I call mass.isotopologues with a 'composition' argument:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">isotopologues</span><span class=\"p\">(</span><span class=\"n\">composition</span><span class=\"o\">=</span><span class=\"n\">composition</span><span class=\"p\">,</span>\n                                               <span class=\"n\">report_abundance</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">,</span>\n                                               <span class=\"n\">isotope_threshold</span><span class=\"o\">=</span><span class=\"n\">isotope_threshold</span><span class=\"p\">,</span>\n                                               <span class=\"n\">overall_threshold</span><span class=\"o\">=</span><span class=\"n\">overall_threshold</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>It causes an error because it passes 2 'composition' kwargs to another function:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"o\">/</span><span class=\"n\">pyteomics</span><span class=\"o\">/</span><span class=\"n\">mass</span><span class=\"o\">/</span><span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">py</span><span class=\"s2\">&quot;, line 715, in isotopologues</span>\n   <span class=\"n\">abundance</span> <span class=\"o\">=</span> <span class=\"n\">isotopic_composition_abundance</span><span class=\"p\">(</span><span class=\"n\">composition</span><span class=\"o\">=</span><span class=\"n\">ic</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n<span class=\"ne\">TypeError</span><span class=\"p\">:</span> <span class=\"n\">isotopic_composition_abundance</span><span class=\"p\">()</span> <span class=\"n\">got</span> <span class=\"n\">multiple</span> <span class=\"n\">values</span> <span class=\"k\">for</span> <span class=\"n\">keyword</span> <span class=\"n\">argument</span> <span class=\"s1\">&#39;composition&#39;</span>\n</pre></div>\n\n\n<p>A similar error also happened with the 'formula' argument.</p>\n<p>This may or may not be the best solution, but it can be fixed by removing 'composition' and 'formula' from kwargs before passing to isotopic_composition_abundance:</p>\n<div class=\"codehilite language-python\"><pre><span></span>    <span class=\"k\">for</span> <span class=\"n\">isotopologue</span> <span class=\"ow\">in</span> <span class=\"n\">product</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">all_isotoplogues</span><span class=\"p\">):</span>\n\n        <span class=\"k\">if</span> <span class=\"s1\">&#39;formula&#39;</span> <span class=\"ow\">in</span> <span class=\"n\">kwargs</span><span class=\"p\">:</span>\n            <span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;formula&#39;</span><span class=\"p\">)</span>\n\n        <span class=\"k\">if</span> <span class=\"s1\">&#39;composition&#39;</span> <span class=\"ow\">in</span> <span class=\"n\">kwargs</span><span class=\"p\">:</span>\n            <span class=\"n\">kwargs</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">&#39;composition&#39;</span><span class=\"p\">)</span>\n\n        <span class=\"n\">ic</span> <span class=\"o\">=</span> <span class=\"n\">Composition</span><span class=\"p\">(</span><span class=\"n\">formula</span><span class=\"o\">=</span><span class=\"s1\">&#39;&#39;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">atom</span> <span class=\"k\">for</span> <span class=\"n\">el</span> <span class=\"ow\">in</span> <span class=\"n\">isotopologue</span> <span class=\"k\">for</span> <span class=\"n\">atom</span> <span class=\"ow\">in</span> <span class=\"n\">el</span><span class=\"p\">),</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">report_abundance</span> <span class=\"ow\">or</span> <span class=\"n\">overall_threshold</span> <span class=\"o\">&gt;</span> <span class=\"mf\">0.0</span><span class=\"p\">:</span>\n            <span class=\"n\">abundance</span> <span class=\"o\">=</span> <span class=\"n\">isotopic_composition_abundance</span><span class=\"p\">(</span><span class=\"n\">composition</span><span class=\"o\">=</span><span class=\"n\">ic</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n</pre></div>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-02-23T22:32:04.711040+00:00", "milestone": null, "updated_on": "2018-03-08T22:19:42.928851+00:00", "type": "issue", "id": 22}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/23/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/23.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/23/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/23/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/23/mzml-xml-huge-text-node-error"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/23/vote"}}, "reporter": {"display_name": "jacobrosenstein", "uuid": "{15b69590-5316-43cf-92b2-426db558db61}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B15b69590-5316-43cf-92b2-426db558db61%7D"}, "html": {"href": "https://bitbucket.org/%7B15b69590-5316-43cf-92b2-426db558db61%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/d3c71a487a958950c1466398730b1f58d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJ-4.png"}}, "nickname": "jacobrosenstein", "type": "user", "account_id": "5a9095b90e69ba52f30623f3"}, "title": "mzML XML \"huge text node\" error", "component": null, "votes": 0, "watches": 1, "content": {"raw": "I am reading some large mzML files, and I am frequently seeing this error:\r\n\r\nXMLSyntaxError: xmlSAX2Characters: huge text node\r\n\r\nI have temporarily gone through mzml.py and xml.py and added the parameter huge_tree=True to all etree.iterparse() methods. This seems to have temporarily fixed it.", "markup": "markdown", "html": "<p>I am reading some large mzML files, and I am frequently seeing this error:</p>\n<p>XMLSyntaxError: xmlSAX2Characters: huge text node</p>\n<p>I have temporarily gone through mzml.py and xml.py and added the parameter huge_tree=True to all etree.iterparse() methods. This seems to have temporarily fixed it.</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-03-01T22:50:33.469631+00:00", "milestone": null, "updated_on": "2018-03-04T17:10:45.443619+00:00", "type": "issue", "id": 23}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/24/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/24.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/24/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/24/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/24/calling-mgfread-with-usage-of-source"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/24/vote"}}, "reporter": null, "title": "calling mgf.read() with usage of source keyword raises IndexError", "component": null, "votes": 0, "watches": null, "content": {"raw": "If I run \r\n\r\n```\r\nmgf.read(source=obsS_MGF_filePath, use_header=True, convert_arrays=1, read_charges=False, dtype=float)\r\n\r\n```\r\nI get \r\n\r\n```\r\n#!File \"/usr/local/lib/python3.5/dist-packages/pyteomics/auxiliary.py\", line 531, in helper return FileReader(args[0], _mode, _func, True, args[1:], kwargs, kwargs.pop('encoding', None)) IndexError: tuple index out of range\r\n\r\nFile \"/usr/local/lib/python3.5/dist-packages/pyteomics/auxiliary.py\", line 531, in helper\r\n    return FileReader(args[0], _mode, _func, True, args[1:], kwargs, kwargs.pop('encoding', None))\r\nIndexError: tuple index out of range\r\n```\r\nBut if I run without explicitly writing the source keyword:\r\n\r\n```\r\nmgf.read(obsS_MGF_filePath, use_header=True, convert_arrays=1, read_charges=False, dtype=float)\r\n\r\n```\r\neverything works just fine. The problem is that the args tuple is empty when you use the source keyword. I strongly advise against using the args tuple in this way, because you are hardcoding your argument order while making it look like you are not (because you specify keywords).", "markup": "markdown", "html": "<p>If I run </p>\n<div class=\"codehilite\"><pre><span></span>mgf.read(source=obsS_MGF_filePath, use_header=True, convert_arrays=1, read_charges=False, dtype=float)\n</pre></div>\n\n\n<p>I get </p>\n<div class=\"codehilite language-file\"><pre><span></span>File &quot;/usr/local/lib/python3.5/dist-packages/pyteomics/auxiliary.py&quot;, line 531, in helper\n    return FileReader(args[0], _mode, _func, True, args[1:], kwargs, kwargs.pop(&#39;encoding&#39;, None))\nIndexError: tuple index out of range\n</pre></div>\n\n\n<p>But if I run without explicitly writing the source keyword:</p>\n<div class=\"codehilite\"><pre><span></span>mgf.read(obsS_MGF_filePath, use_header=True, convert_arrays=1, read_charges=False, dtype=float)\n</pre></div>\n\n\n<p>everything works just fine. The problem is that the args tuple is empty when you use the source keyword. I strongly advise against using the args tuple in this way, because you are hardcoding your argument order while making it look like you are not (because you specify keywords).</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-05-04T09:41:54.914905+00:00", "milestone": null, "updated_on": "2018-05-11T15:07:42.172418+00:00", "type": "issue", "id": 24}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/25/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/25.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/25/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/25/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/25/pyteomics-34-incompatible-with-current"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/25/vote"}}, "reporter": {"display_name": "mglubber", "uuid": "{559bde61-bb9f-484b-b183-1b21bb8b4bb0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B559bde61-bb9f-484b-b183-1b21bb8b4bb0%7D"}, "html": {"href": "https://bitbucket.org/%7B559bde61-bb9f-484b-b183-1b21bb8b4bb0%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/f188803c05340901eba88626b4b308d9d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsM-0.png"}}, "nickname": "mglubber", "type": "user", "account_id": "5af0862cfd53c72c28995f3f"}, "title": "pyteomics 3.4 incompatible with current versions of pepxmltk and cythonize", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Installing pyteomics with conda (from the bioconda channel) installs version 3.4, which appears to incompatible with the current versions of pyteomics.pepxmltk and pyteomics.cythonize available through pip. E.g.\r\n\r\n```\r\n#!bash\r\nconda create --name some_env python=2.7 -c bioconda pyteomics\r\nconda activate some_env\r\npip install pyteomics.pepxmltk\r\n```\r\nWill give an ```ImportError``` if I try to use pyteomics, e.g.\r\n```\r\n#!python\r\n>>> from pyteomics import mass\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nImportError: cannot import name mass\r\n```\r\nThe same error occurs if pyteomics.cythonize is installed instead of pepxmltk.\r\n\r\nHowever, if I install both pyteomics and the additional modules through pip, pyteomics version 3.4.2 is installed and everything works correctly.\r\n```\r\n#!bash\r\nconda create --name some_env python=2.7\r\nconda activate some_env\r\npip install pyteomics pyteomics.pepxmltk\r\n```\r\n```\r\n#!python\r\n>>> from pyteomics import mass\r\n>>> mass.calculate_mass(formula=\"H2O\")\r\n18.0105646837\r\n```\r\nInstalling just pyteomics through conda without any additional modules also works correctly.", "markup": "markdown", "html": "<p>Installing pyteomics with conda (from the bioconda channel) installs version 3.4, which appears to incompatible with the current versions of pyteomics.pepxmltk and pyteomics.cythonize available through pip. E.g.</p>\n<div class=\"codehilite language-bash\"><pre><span></span>conda create --name some_env <span class=\"nv\">python</span><span class=\"o\">=</span><span class=\"m\">2</span>.7 -c bioconda pyteomics\nconda activate some_env\npip install pyteomics.pepxmltk\n</pre></div>\n\n\n<p>Will give an <code>ImportError</code> if I try to use pyteomics, e.g.</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pyteomics</span> <span class=\"kn\">import</span> <span class=\"n\">mass</span>\n<span class=\"n\">Traceback</span> <span class=\"p\">(</span><span class=\"n\">most</span> <span class=\"n\">recent</span> <span class=\"n\">call</span> <span class=\"n\">last</span><span class=\"p\">):</span>\n  <span class=\"n\">File</span> <span class=\"s2\">&quot;&lt;stdin&gt;&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"o\">&lt;</span><span class=\"n\">module</span><span class=\"o\">&gt;</span>\n<span class=\"ne\">ImportError</span><span class=\"p\">:</span> <span class=\"n\">cannot</span> <span class=\"kn\">import</span> <span class=\"nn\">name</span> <span class=\"nn\">mass</span>\n</pre></div>\n\n\n<p>The same error occurs if pyteomics.cythonize is installed instead of pepxmltk.</p>\n<p>However, if I install both pyteomics and the additional modules through pip, pyteomics version 3.4.2 is installed and everything works correctly.</p>\n<div class=\"codehilite language-bash\"><pre><span></span>conda create --name some_env <span class=\"nv\">python</span><span class=\"o\">=</span><span class=\"m\">2</span>.7\nconda activate some_env\npip install pyteomics pyteomics.pepxmltk\n</pre></div>\n\n\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pyteomics</span> <span class=\"kn\">import</span> <span class=\"n\">mass</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">calculate_mass</span><span class=\"p\">(</span><span class=\"n\">formula</span><span class=\"o\">=</span><span class=\"s2\">&quot;H2O&quot;</span><span class=\"p\">)</span>\n<span class=\"mf\">18.0105646837</span>\n</pre></div>\n\n\n<p>Installing just pyteomics through conda without any additional modules also works correctly.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-05-07T20:52:03.480199+00:00", "milestone": null, "updated_on": "2018-06-07T10:32:13.476239+00:00", "type": "issue", "id": 25}, {"priority": "minor", "kind": "proposal", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/26/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/26.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/26/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/26/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/26/mzxml-reader"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/26/vote"}}, "reporter": null, "title": "mzXML reader", "component": null, "votes": 0, "watches": null, "content": {"raw": "Hi,\r\nThanks a lot for creating the library.\r\nThis is actually not an issue, but rather a question on how to use 'mzxml' the mzXML reader.\r\n\r\nThe following code is from your tutorial (with slight modification):\r\n\r\n```\r\n#!python\r\n\r\nfrom pyteomics import mzxml, auxiliary\r\nwith mzxml.read('tests/test.mzXML') as reader:\r\n    auxiliary.print_tree(next(reader))\r\n```\r\n\r\n\r\nThe code works. However, I could not find any other example code to allow me to use the 'mzxml' module. I would like to read a spectrum using the 'get_by_id' method as stated on this page:\r\nhttps://pythonhosted.org/pyteomics/api/mzxml.html#module-pyteomics.mzxml\r\n\r\nIf anyone can provide a simple example code I would greatly appreciate it.\r\n\r\nThanks a lot again.", "markup": "markdown", "html": "<p>Hi,\nThanks a lot for creating the library.\nThis is actually not an issue, but rather a question on how to use 'mzxml' the mzXML reader.</p>\n<p>The following code is from your tutorial (with slight modification):</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">pyteomics</span> <span class=\"kn\">import</span> <span class=\"n\">mzxml</span><span class=\"p\">,</span> <span class=\"n\">auxiliary</span>\n<span class=\"k\">with</span> <span class=\"n\">mzxml</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"s1\">&#39;tests/test.mzXML&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">reader</span><span class=\"p\">:</span>\n    <span class=\"n\">auxiliary</span><span class=\"o\">.</span><span class=\"n\">print_tree</span><span class=\"p\">(</span><span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"n\">reader</span><span class=\"p\">))</span>\n</pre></div>\n\n\n<p>The code works. However, I could not find any other example code to allow me to use the 'mzxml' module. I would like to read a spectrum using the 'get_by_id' method as stated on this page:\n<a href=\"https://pythonhosted.org/pyteomics/api/mzxml.html#module-pyteomics.mzxml\" rel=\"nofollow\" class=\"ap-connect-link\">https://pythonhosted.org/pyteomics/api/mzxml.html#module-pyteomics.mzxml</a></p>\n<p>If anyone can provide a simple example code I would greatly appreciate it.</p>\n<p>Thanks a lot again.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-05-09T20:15:34.924297+00:00", "milestone": null, "updated_on": "2018-05-11T15:07:05.242365+00:00", "type": "issue", "id": 26}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/27/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/27.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/27/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/27/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/27/xml_retrieve_refs-is-undefined"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/27/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "`XML._retrieve_refs` is undefined", "component": null, "votes": 0, "watches": 1, "content": {"raw": "In the base class for `XML`, there is a block at [line 381](#!/levitsky/pyteomics/src/bb94d1353d72604e635db1299910f767a02227a4/pyteomics/xml.py?at=default#xml.py-381) that calls a method called `_retrieve_refs`. This method isn't defined on `XML`, only on the `MzIdentML` subclass`. \r\n\r\nI'll open a PR shortly to fix the issue.", "markup": "markdown", "html": "<p>In the base class for <code>XML</code>, there is a block at <a data-is-external-link=\"true\" href=\"#!/levitsky/pyteomics/src/bb94d1353d72604e635db1299910f767a02227a4/pyteomics/xml.py?at=default#xml.py-381\" rel=\"nofollow\">line 381</a> that calls a method called <code>_retrieve_refs</code>. This method isn't defined on <code>XML</code>, only on the <code>MzIdentML</code> subclass`. </p>\n<p>I'll open a PR shortly to fix the issue.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-05-21T13:47:44.963239+00:00", "milestone": null, "updated_on": "2018-05-21T15:16:37.157310+00:00", "type": "issue", "id": 27}, {"priority": "minor", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/28/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/28.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/28/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/28/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/28/z-ion-type-masses"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/28/vote"}}, "reporter": null, "title": "z ion-type masses", "component": null, "votes": 0, "watches": null, "content": {"raw": "Hello, Pyteomics Team\r\n\r\nI am a current chemsitry graduate student at the University of Michigan using pyteomics for top-down sequencing. I used one of your combined examples: https://pythonhosted.org/pyteomics/examples/example_msms.html\r\n\r\nI obtain the list of z-ions from a sequence, but when I compare them to the z-ions obtained from the same sequence from the MS-Product section of Protein-Prospector (http://prospector.ucsf.edu/prospector/mshome.htm), the z-ions produced by pyteomics are one hydrogen mass lower. Has somebody else experience this? Is this related to z'+ vs z(superscript dot) +, radical/even-electron pairs for c and z ions?\r\n\r\nThanks for your attention, \r\n\r\nCarolina Rojas Ramirez\r\n\r\nGraduate Student\r\n\r\nDepartment of Chemistry\r\n\r\nUniversity of Michigan", "markup": "markdown", "html": "<p>Hello, Pyteomics Team</p>\n<p>I am a current chemsitry graduate student at the University of Michigan using pyteomics for top-down sequencing. I used one of your combined examples: <a href=\"https://pythonhosted.org/pyteomics/examples/example_msms.html\" rel=\"nofollow\" class=\"ap-connect-link\">https://pythonhosted.org/pyteomics/examples/example_msms.html</a></p>\n<p>I obtain the list of z-ions from a sequence, but when I compare them to the z-ions obtained from the same sequence from the MS-Product section of Protein-Prospector (<a href=\"http://prospector.ucsf.edu/prospector/mshome.htm\" rel=\"nofollow\" class=\"ap-connect-link\">http://prospector.ucsf.edu/prospector/mshome.htm</a>), the z-ions produced by pyteomics are one hydrogen mass lower. Has somebody else experience this? Is this related to z'+ vs z(superscript dot) +, radical/even-electron pairs for c and z ions?</p>\n<p>Thanks for your attention, </p>\n<p>Carolina Rojas Ramirez</p>\n<p>Graduate Student</p>\n<p>Department of Chemistry</p>\n<p>University of Michigan</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-05-25T00:03:02.800427+00:00", "milestone": null, "updated_on": "2018-06-06T19:11:47.668716+00:00", "type": "issue", "id": 28}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/29/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/29.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/29/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/29/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/29/trypsin-digestion-is-not-quite-correct"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/29/vote"}}, "reporter": {"display_name": "Ian Castleden", "uuid": "{7de07194-6ca1-4d30-9697-51837f19d3a6}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7de07194-6ca1-4d30-9697-51837f19d3a6%7D"}, "html": {"href": "https://bitbucket.org/%7B7de07194-6ca1-4d30-9697-51837f19d3a6%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:79dfa78f-e29e-4a58-b214-4c2e2985e047/ba2e0c12-205a-40e0-8eaa-880bd1e6a600/128"}}, "nickname": "athaliana", "type": "user", "account_id": "557058:79dfa78f-e29e-4a58-b214-4c2e2985e047"}, "title": "Trypsin digestion is not quite correct", "component": null, "votes": 0, "watches": 1, "content": {"raw": "According to Expasy, trypsin digestion has some exceptions:\r\nhttps://web.expasy.org/peptide_cutter/peptidecutter_enzymes.html#exceptions\r\n\r\nIt would be good to fold the exceptions into the RE but\r\nthis is beyond me....\r\n\r\nThis is possibly more correct in the `_cleave` code:\r\n\r\n```\r\n#!python\r\n\r\nexc = re.compile(r'((?<=[CD])K(?=D))|((?<=C)K(?=[HY]))|((?<=C)R(?=K))|((?<=R)R(?=[HR]))')\r\n\r\ndef trypsin_exception(i, seq):\r\n    m = exc.search(seq, max(0, i - 2), i + 1)\r\n    return bool(m)\r\n     \r\n\r\n[x.end() for x in re.finditer(trypsin, seq) if not trypsin_exception(x.end(),  seq)]\r\n```", "markup": "markdown", "html": "<p>According to Expasy, trypsin digestion has some exceptions:\n<a href=\"https://web.expasy.org/peptide_cutter/peptidecutter_enzymes.html#exceptions\" rel=\"nofollow\" class=\"ap-connect-link\">https://web.expasy.org/peptide_cutter/peptidecutter_enzymes.html#exceptions</a></p>\n<p>It would be good to fold the exceptions into the RE but\nthis is beyond me....</p>\n<p>This is possibly more correct in the <code>_cleave</code> code:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">exc</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">&#39;((?&lt;=[CD])K(?=D))|((?&lt;=C)K(?=[HY]))|((?&lt;=C)R(?=K))|((?&lt;=R)R(?=[HR]))&#39;</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">trypsin_exception</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">seq</span><span class=\"p\">):</span>\n    <span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"n\">exc</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">seq</span><span class=\"p\">,</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">i</span> <span class=\"o\">-</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"nb\">bool</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"p\">)</span>\n\n\n<span class=\"p\">[</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">end</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">finditer</span><span class=\"p\">(</span><span class=\"n\">trypsin</span><span class=\"p\">,</span> <span class=\"n\">seq</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">trypsin_exception</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">end</span><span class=\"p\">(),</span>  <span class=\"n\">seq</span><span class=\"p\">)]</span>\n</pre></div>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-07-07T03:33:37.733337+00:00", "milestone": null, "updated_on": "2018-07-18T18:51:55.927942+00:00", "type": "issue", "id": 29}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/30/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/30.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/30/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/30/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/30/cant-add-other-decoy-label"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/30/vote"}}, "reporter": null, "title": "Can't add other decoy label", "component": null, "votes": 0, "watches": null, "content": {"raw": "Hi,\r\n\r\nI have performed an entrapment experiment with X!Tandem. All target labels start with\r\n\">generic|T_\" and all decoy labels start with \">generic|D_\". \r\nUsing Pyteomics I have read them with tandem.TandemXML(result.t.xml)  and now I need to filter them using an FDR threshold. Therefore, I use tandem.filter(result.t.xml, fdr=0.05, is_decoy = \"D_\"), but it throws a KeyError: KeyError: 'D_'.\r\n\r\nHow can I solve this?\r\n\r\nThanks in advance!", "markup": "markdown", "html": "<p>Hi,</p>\n<p>I have performed an entrapment experiment with X!Tandem. All target labels start with\n\"&gt;generic|T_\" and all decoy labels start with \"&gt;generic|D_\". \nUsing Pyteomics I have read them with tandem.TandemXML(result.t.xml)  and now I need to filter them using an FDR threshold. Therefore, I use tandem.filter(result.t.xml, fdr=0.05, is_decoy = \"D_\"), but it throws a KeyError: KeyError: 'D_'.</p>\n<p>How can I solve this?</p>\n<p>Thanks in advance!</p>", "type": "rendered"}, "assignee": null, "state": "closed", "version": null, "edited_on": null, "created_on": "2018-07-18T13:36:41.064072+00:00", "milestone": null, "updated_on": "2018-08-06T17:10:20.900560+00:00", "type": "issue", "id": 30}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/31/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/31.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/31/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/31/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/31/fast-way-to-retrieve-all-spectra"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/31/vote"}}, "reporter": null, "title": "Fast way to retrieve all spectra", "component": null, "votes": 0, "watches": null, "content": {"raw": "Hi,\r\n\r\nI was wondering if there is a faster way to get all identifications back, without applying FDR?\r\nI am using now the following line of code for that:\r\n\r\n```\r\n#!python\r\ntandem.filter('results.t.xml', fdr=1)\r\n```\r\n\r\nIt returns about 10000 psms with FDR = 1 (so, I thought all ms/ms spectra)\r\nHowever, if I look to my mgf file, there are about 15000 spectra over there. How does it come that with FDR = 1 this number is not the same? And, how could this be improved?\r\n\r\nKind regards, \r\nTim", "markup": "markdown", "html": "<p>Hi,</p>\n<p>I was wondering if there is a faster way to get all identifications back, without applying FDR?\nI am using now the following line of code for that:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">tandem</span><span class=\"o\">.</span><span class=\"n\">filter</span><span class=\"p\">(</span><span class=\"s1\">&#39;results.t.xml&#39;</span><span class=\"p\">,</span> <span class=\"n\">fdr</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>It returns about 10000 psms with FDR = 1 (so, I thought all ms/ms spectra)\nHowever, if I look to my mgf file, there are about 15000 spectra over there. How does it come that with FDR = 1 this number is not the same? And, how could this be improved?</p>\n<p>Kind regards, \nTim</p>", "type": "rendered"}, "assignee": null, "state": "closed", "version": null, "edited_on": null, "created_on": "2018-08-02T14:50:41.340994+00:00", "milestone": null, "updated_on": "2018-08-24T12:24:27.581459+00:00", "type": "issue", "id": 31}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/32/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/32.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/32/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/32/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/32/pyteomicsbiolccc-documentation-page-dead"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/32/vote"}}, "reporter": null, "title": "pyteomics.biolccc documentation page dead link", "component": null, "votes": 0, "watches": null, "content": {"raw": "I'm not sure if the link has changed, but the link for BioLCCC documentation (https://pythonhosted.org/pyteomics.biolccc/) is dead. Just wanted to notify!", "markup": "markdown", "html": "<p>I'm not sure if the link has changed, but the link for BioLCCC documentation (<a href=\"https://pythonhosted.org/pyteomics.biolccc/\" rel=\"nofollow\" class=\"ap-connect-link\">https://pythonhosted.org/pyteomics.biolccc/</a>) is dead. Just wanted to notify!</p>", "type": "rendered"}, "assignee": null, "state": "closed", "version": null, "edited_on": null, "created_on": "2018-08-23T15:45:35.357471+00:00", "milestone": null, "updated_on": "2018-08-29T19:54:55.792499+00:00", "type": "issue", "id": 32}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/33/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/33.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/33/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/33/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/33/problems-w-creating-dataframe-from-xtandem"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/33/vote"}}, "reporter": null, "title": "Problems w/ creating DataFrame from X!Tandem file", "component": null, "votes": 0, "watches": null, "content": {"raw": "Hello,\r\n\r\nI have run into a problem using tandem.DataFrame() to read an X!Tandem output file.  In particular, a KeyError is raised at the statement near the end of the above mentioned routine at the statement:\r\n\r\n            del protein['peptide']['peptide']\r\n\r\nIf I wrap this in a try block then I hit another KeyError at \r\n\r\n            info['scan'] = item['support']['fragment ion mass spectrum']['note']\r\n\r\nHere is the error message:\r\n\r\n\r\n```\r\nbash-3.2$ ./CuWm_analysis.py -i foo.xml -f 'X!Tandem'\r\nTraceback (most recent call last):\r\n  File \"./CuWm_analysis.py\", line 47, in <module>\r\n    sys.exit(main(ns))\r\n  File \"./CuWm_analysis.py\", line 33, in main\r\n    unprocessed = supported_formats[ns.format].DataFrame(ns.infile)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pyteomics/tandem.py\", line 310, in DataFrame\r\n    del protein['peptide']['peptide']\r\nKeyError: 'peptide'\r\n```", "markup": "markdown", "html": "<p>Hello,</p>\n<p>I have run into a problem using tandem.DataFrame() to read an X!Tandem output file.  In particular, a KeyError is raised at the statement near the end of the above mentioned routine at the statement:</p>\n<div class=\"codehilite\"><pre><span></span>        del protein[&#39;peptide&#39;][&#39;peptide&#39;]\n</pre></div>\n\n\n<p>If I wrap this in a try block then I hit another KeyError at </p>\n<div class=\"codehilite\"><pre><span></span>        info[&#39;scan&#39;] = item[&#39;support&#39;][&#39;fragment ion mass spectrum&#39;][&#39;note&#39;]\n</pre></div>\n\n\n<p>Here is the error message:</p>\n<div class=\"codehilite\"><pre><span></span>bash-3.2$ ./CuWm_analysis.py -i foo.xml -f &#39;X!Tandem&#39;\nTraceback (most recent call last):\n  File &quot;./CuWm_analysis.py&quot;, line 47, in &lt;module&gt;\n    sys.exit(main(ns))\n  File &quot;./CuWm_analysis.py&quot;, line 33, in main\n    unprocessed = supported_formats[ns.format].DataFrame(ns.infile)\n  File &quot;/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pyteomics/tandem.py&quot;, line 310, in DataFrame\n    del protein[&#39;peptide&#39;][&#39;peptide&#39;]\nKeyError: &#39;peptide&#39;\n</pre></div>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-10-29T21:09:36.521506+00:00", "milestone": null, "updated_on": "2019-01-07T15:48:27.068073+00:00", "type": "issue", "id": 33}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/34/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/34.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/34/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/34/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/34/parser-fails-on-numbers-in-modx-sequence"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/34/vote"}}, "reporter": {"display_name": "Lars Kolbowski", "uuid": "{fc1df402-e755-41a0-b5a6-d80421a2af72}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bfc1df402-e755-41a0-b5a6-d80421a2af72%7D"}, "html": {"href": "https://bitbucket.org/%7Bfc1df402-e755-41a0-b5a6-d80421a2af72%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5bc99e3bd64558662e6d627e/dab57bdc-7f90-48ff-9610-606fbf956a58/128"}}, "nickname": "Lars Kolbowski", "type": "user", "account_id": "5bc99e3bd64558662e6d627e"}, "title": "parser fails on numbers in modX sequence", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Hi there, \r\n\r\nI'm trying to use pyteomics to calculate masses including modifcations in modX syntax.\r\nThe documentation states:\r\n\r\n\"The labels (or codes) for the 20 standard amino acids in modX are the same as in IUPAC nomeclature. A label for a modified amino acid has a general form of \u2018modX\u2019, i.e.:\r\n\r\n**it starts with an arbitrary number of lower-case symbols or numbers** (a modification);\r\nit ends with a single upper-case symbol (an amino acid residue).\"\r\n\r\nBut when I include numbers in my modifications the script crashes. See example below:\r\n\r\n\r\n```\r\n#!python\r\n\r\nfrom pyteomics import mass\r\nmod_compositions = {'bs3oh': mass.Composition('C8H12O3')}\r\naa_compositions = dict(mass.std_aa_comp)\r\naa_compositions.update(mod_compositions)\r\nmass.calculate_mass(sequence='LAbs3ohK', aa_comp=aa_compositions)\r\n```\r\n\r\n\r\n```\r\n#!python\r\n\r\n  File \"/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/parser.py\", line 275, in parse\r\n    n, body, c = re.match(_modX_sequence, sequence).groups()\r\nAttributeError: 'NoneType' object has no attribute 'groups'\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-14-4fecb2be2899>\", line 8, in <module>\r\n    mass.calculate_mass(sequence='LAbs3ohK', aa_comp=aa_compositions)\r\n  File \"/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/mass/mass.py\", line 506, in calculate_mass\r\n    else Composition(*args, **kwargs))\r\n  File \"/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/mass/mass.py\", line 294, in __init__\r\n    mass_data if kwa == 'formula' else aa_comp)\r\n  File \"/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/mass/mass.py\", line 200, in _from_sequence\r\n    show_unmodified_termini=True)\r\n  File \"/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/parser.py\", line 277, in parse\r\n    raise PyteomicsError('Not a valid modX sequence: ' + sequence)\r\npyteomics.auxiliary.structures.PyteomicsError: Pyteomics error, message: 'Not a valid modX sequence: LAbs3ohK'\r\n```", "markup": "markdown", "html": "<p>Hi there, </p>\n<p>I'm trying to use pyteomics to calculate masses including modifcations in modX syntax.\nThe documentation states:</p>\n<p>\"The labels (or codes) for the 20 standard amino acids in modX are the same as in IUPAC nomeclature. A label for a modified amino acid has a general form of \u2018modX\u2019, i.e.:</p>\n<p><strong>it starts with an arbitrary number of lower-case symbols or numbers</strong> (a modification);\nit ends with a single upper-case symbol (an amino acid residue).\"</p>\n<p>But when I include numbers in my modifications the script crashes. See example below:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">pyteomics</span> <span class=\"kn\">import</span> <span class=\"n\">mass</span>\n<span class=\"n\">mod_compositions</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">&#39;bs3oh&#39;</span><span class=\"p\">:</span> <span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">Composition</span><span class=\"p\">(</span><span class=\"s1\">&#39;C8H12O3&#39;</span><span class=\"p\">)}</span>\n<span class=\"n\">aa_compositions</span> <span class=\"o\">=</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">std_aa_comp</span><span class=\"p\">)</span>\n<span class=\"n\">aa_compositions</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">mod_compositions</span><span class=\"p\">)</span>\n<span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">calculate_mass</span><span class=\"p\">(</span><span class=\"n\">sequence</span><span class=\"o\">=</span><span class=\"s1\">&#39;LAbs3ohK&#39;</span><span class=\"p\">,</span> <span class=\"n\">aa_comp</span><span class=\"o\">=</span><span class=\"n\">aa_compositions</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<div class=\"codehilite language-python\"><pre><span></span>  <span class=\"n\">File</span> <span class=\"s2\">&quot;/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/parser.py&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">275</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">parse</span>\n    <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">body</span><span class=\"p\">,</span> <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">match</span><span class=\"p\">(</span><span class=\"n\">_modX_sequence</span><span class=\"p\">,</span> <span class=\"n\">sequence</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">groups</span><span class=\"p\">()</span>\n<span class=\"ne\">AttributeError</span><span class=\"p\">:</span> <span class=\"s1\">&#39;NoneType&#39;</span> <span class=\"nb\">object</span> <span class=\"n\">has</span> <span class=\"n\">no</span> <span class=\"n\">attribute</span> <span class=\"s1\">&#39;groups&#39;</span>\n<span class=\"n\">During</span> <span class=\"n\">handling</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">above</span> <span class=\"n\">exception</span><span class=\"p\">,</span> <span class=\"n\">another</span> <span class=\"n\">exception</span> <span class=\"n\">occurred</span><span class=\"p\">:</span>\n<span class=\"n\">Traceback</span> <span class=\"p\">(</span><span class=\"n\">most</span> <span class=\"n\">recent</span> <span class=\"n\">call</span> <span class=\"n\">last</span><span class=\"p\">):</span>\n  <span class=\"n\">File</span> <span class=\"s2\">&quot;/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/IPython/core/interactiveshell.py&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">3267</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">run_code</span>\n    <span class=\"k\">exec</span><span class=\"p\">(</span><span class=\"n\">code_obj</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">user_global_ns</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">user_ns</span><span class=\"p\">)</span>\n  <span class=\"n\">File</span> <span class=\"s2\">&quot;&lt;ipython-input-14-4fecb2be2899&gt;&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"o\">&lt;</span><span class=\"n\">module</span><span class=\"o\">&gt;</span>\n    <span class=\"n\">mass</span><span class=\"o\">.</span><span class=\"n\">calculate_mass</span><span class=\"p\">(</span><span class=\"n\">sequence</span><span class=\"o\">=</span><span class=\"s1\">&#39;LAbs3ohK&#39;</span><span class=\"p\">,</span> <span class=\"n\">aa_comp</span><span class=\"o\">=</span><span class=\"n\">aa_compositions</span><span class=\"p\">)</span>\n  <span class=\"n\">File</span> <span class=\"s2\">&quot;/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/mass/mass.py&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">506</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">calculate_mass</span>\n    <span class=\"k\">else</span> <span class=\"n\">Composition</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">))</span>\n  <span class=\"n\">File</span> <span class=\"s2\">&quot;/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/mass/mass.py&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">294</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"fm\">__init__</span>\n    <span class=\"n\">mass_data</span> <span class=\"k\">if</span> <span class=\"n\">kwa</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;formula&#39;</span> <span class=\"k\">else</span> <span class=\"n\">aa_comp</span><span class=\"p\">)</span>\n  <span class=\"n\">File</span> <span class=\"s2\">&quot;/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/mass/mass.py&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">_from_sequence</span>\n    <span class=\"n\">show_unmodified_termini</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n  <span class=\"n\">File</span> <span class=\"s2\">&quot;/home/lars/.local/share/virtualenvs/6gmOU3S_/lib/python3.6/site-packages/pyteomics/parser.py&quot;</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">277</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">parse</span>\n    <span class=\"k\">raise</span> <span class=\"n\">PyteomicsError</span><span class=\"p\">(</span><span class=\"s1\">&#39;Not a valid modX sequence: &#39;</span> <span class=\"o\">+</span> <span class=\"n\">sequence</span><span class=\"p\">)</span>\n<span class=\"n\">pyteomics</span><span class=\"o\">.</span><span class=\"n\">auxiliary</span><span class=\"o\">.</span><span class=\"n\">structures</span><span class=\"o\">.</span><span class=\"n\">PyteomicsError</span><span class=\"p\">:</span> <span class=\"n\">Pyteomics</span> <span class=\"n\">error</span><span class=\"p\">,</span> <span class=\"n\">message</span><span class=\"p\">:</span> <span class=\"s1\">&#39;Not a valid modX sequence: LAbs3ohK&#39;</span>\n</pre></div>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-11-13T11:04:07.459206+00:00", "milestone": null, "updated_on": "2018-11-13T18:17:48.975494+00:00", "type": "issue", "id": 34}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/35/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/35.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/35/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/35/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/35/ordereddict-may-be-in-reversed-order-on"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/35/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "OrderedDict may be in reversed order on Py3.5", "component": null, "votes": 0, "watches": 1, "content": {"raw": "While updating some tests to work with the new release, I noticed that tests assuming that the offset index of a file were ordered started failing on Python 3.5 while still passing on 2.7 and 3.6. \r\n\r\n```python\r\nfrom pyteomics import mzml\r\n\r\nreader = mzml.MzML(\"three_test_scans.mzML\", use_index=True)\r\nindex = reader.index['spectrum']\r\nprint(index)\r\n```\r\nProduces:\r\n```\r\nOffsetIndex([('controllerType=0 controllerNumber=1 scan=10014', 3799), \r\n('controllerType=0 controllerNumber=1 scan=10016', 188056),\r\n('controllerType=0 controllerNumber=1 scan=10015', 158797)])\r\n```\r\nwith lines manually wrapped for convenience.\r\n\r\nThe order may be permuted randomly. When tested with a larger file, there are no issues.", "markup": "markdown", "html": "<p>While updating some tests to work with the new release, I noticed that tests assuming that the offset index of a file were ordered started failing on Python 3.5 while still passing on 2.7 and 3.6. </p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">pyteomics</span> <span class=\"kn\">import</span> <span class=\"n\">mzml</span>\n\n<span class=\"n\">reader</span> <span class=\"o\">=</span> <span class=\"n\">mzml</span><span class=\"o\">.</span><span class=\"n\">MzML</span><span class=\"p\">(</span><span class=\"s2\">&quot;three_test_scans.mzML&quot;</span><span class=\"p\">,</span> <span class=\"n\">use_index</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n<span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">reader</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">[</span><span class=\"s1\">&#39;spectrum&#39;</span><span class=\"p\">]</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>Produces:</p>\n<div class=\"codehilite\"><pre><span></span>OffsetIndex([(&#39;controllerType=0 controllerNumber=1 scan=10014&#39;, 3799), \n(&#39;controllerType=0 controllerNumber=1 scan=10016&#39;, 188056),\n(&#39;controllerType=0 controllerNumber=1 scan=10015&#39;, 158797)])\n</pre></div>\n\n\n<p>with lines manually wrapped for convenience.</p>\n<p>The order may be permuted randomly. When tested with a larger file, there are no issues.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-01-06T22:54:11.975436+00:00", "milestone": null, "updated_on": "2019-01-07T15:51:46.618204+00:00", "type": "issue", "id": 35}, {"priority": "trivial", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/36/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/36.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/36/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/36/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/36/testing-parser-tutorial"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/36/vote"}}, "reporter": {"display_name": "Brian Wiley", "uuid": "{3eb06765-8a88-4877-8286-167d6df93816}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3eb06765-8a88-4877-8286-167d6df93816%7D"}, "html": {"href": "https://bitbucket.org/%7B3eb06765-8a88-4877-8286-167d6df93816%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b37d880573550728f14842f9480016fad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsBW-0.png"}}, "nickname": "BJWiley23", "type": "user", "account_id": "5c776d75efc9686293ac14d5"}, "title": "Testing Parser Tutorial", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Hi,\r\n\r\nI was testing the parser tutorial and for >>> parser.is_modX('pTx')  I am getting True in python 3.7 when your tutorial says False.  Should your tutorial say True?  It is matching against re.compile(r'([^A-Z-]*)([A-Z])') and looking at the explanation page [here](http://rick.measham.id.au/paste/explain.pl?regex=r%27%28%5B%5EA-Z-%5D*%29%28%5BA-Z%5D%29%27) it says:\r\n [^A-Z-]*               any character except: 'A' to 'Z', '-' (0\r\n                             or more times (matching the most amount\r\n                             possible))\r\n\r\nso if I basically type in anything but all lower case letters for the second [A-Z] I will get True because numbers matches the any character besides 'A' to 'Z', '-' 0 or more times\r\n\r\n\r\n```\r\n'brianisnumbeR1' returns True (don't think this is a mod)\r\n'RTTTSaaa444' returns True (same not a mod)\r\n'abcd' returns False as it should\r\n'aa' returns False as it should\r\n```\r\n\r\n\r\nShould this line from pyteomics.parser file be changed? line 208 for me.\r\n```\r\n_modX_split = re.compile(r'([^A-Z-]*)([A-Z])')\r\n```", "markup": "markdown", "html": "<p>Hi,</p>\n<p>I was testing the parser tutorial and for &gt;&gt;&gt; parser.is_modX('pTx')  I am getting True in python 3.7 when your tutorial says False.  Should your tutorial say True?  It is matching against re.compile(r'([^A-Z-]<em>)([A-Z])') and looking at the explanation page <a data-is-external-link=\"true\" href=\"http://rick.measham.id.au/paste/explain.pl?regex=r%27%28%5B%5EA-Z-%5D*%29%28%5BA-Z%5D%29%27\" rel=\"nofollow\">here</a> it says:\n [^A-Z-]</em>               any character except: 'A' to 'Z', '-' (0\n                             or more times (matching the most amount\n                             possible))</p>\n<p>so if I basically type in anything but all lower case letters for the second [A-Z] I will get True because numbers matches the any character besides 'A' to 'Z', '-' 0 or more times</p>\n<div class=\"codehilite\"><pre><span></span>&#39;brianisnumbeR1&#39; returns True (don&#39;t think this is a mod)\n&#39;RTTTSaaa444&#39; returns True (same not a mod)\n&#39;abcd&#39; returns False as it should\n&#39;aa&#39; returns False as it should\n</pre></div>\n\n\n<p>Should this line from pyteomics.parser file be changed? line 208 for me.</p>\n<div class=\"codehilite\"><pre><span></span>_modX_split = re.compile(r&#39;([^A-Z-]*)([A-Z])&#39;)\n</pre></div>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-02-28T05:27:09.942920+00:00", "milestone": null, "updated_on": "2019-02-28T09:39:55.515064+00:00", "type": "issue", "id": 36}, {"priority": "major", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/37/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/37.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/37/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/37/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/37/add-numpress-support-in-mzml"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/37/vote"}}, "reporter": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "title": "Add numpress support in mzML", "component": null, "votes": 0, "watches": 2, "content": {"raw": "Binary data in mzML files can be compressed using numpress algorithms [[1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4047472/)] e.g. with MSConvert. Such mzML files cannot be parsed with pyteomics.\r\n\r\nIt looks like support for those compression types can be added using the Python implementation in [[2](https://github.com/ms-numpress/ms-numpress)].", "markup": "markdown", "html": "<p>Binary data in mzML files can be compressed using numpress algorithms [<a data-is-external-link=\"true\" href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4047472/\" rel=\"nofollow\">1</a>] e.g. with MSConvert. Such mzML files cannot be parsed with pyteomics.</p>\n<p>It looks like support for those compression types can be added using the Python implementation in [<a data-is-external-link=\"true\" href=\"https://github.com/ms-numpress/ms-numpress\" rel=\"nofollow\">2</a>].</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-04-01T19:43:45.233168+00:00", "milestone": null, "updated_on": "2019-06-19T13:24:34.033383+00:00", "type": "issue", "id": 37}, {"priority": "major", "kind": "task", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/38/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/38.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/38/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/38/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/38/unable-to-modify-mz-intensity-arrays"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/38/vote"}}, "reporter": {"display_name": "Wout Bittremieux", "uuid": "{a576c043-433d-4960-93db-d08db5950f23}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Ba576c043-433d-4960-93db-d08db5950f23%7D"}, "html": {"href": "https://bitbucket.org/%7Ba576c043-433d-4960-93db-d08db5950f23%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:93debcd3-22a4-4700-93d1-8301e5013876/5a07f10e-f3c9-4442-9bc8-1831fe9ceaec/128"}}, "nickname": "bittremieux", "type": "user", "account_id": "557058:93debcd3-22a4-4700-93d1-8301e5013876"}, "title": "Unable to modify mz/intensity arrays", "component": null, "votes": 0, "watches": 1, "content": {"raw": "When using NumPy version 1.16+ arrays created from strings cannot be modified: https://github.com/numpy/numpy/pull/11739\r\n\r\nThis is exactly what happens in [line 161 & 162 in `xml.py`](#!/levitsky/pyteomics/src/decec05d63d7528342522a5ec2c9f1b22c41ffc3/pyteomics/xml.py?at=default#xml.py-161,162). As a result, there is an error when trying to modify m/z and intensity arrays.", "markup": "markdown", "html": "<p>When using NumPy version 1.16+ arrays created from strings cannot be modified: <a href=\"https://github.com/numpy/numpy/pull/11739\" rel=\"nofollow\" class=\"ap-connect-link\">https://github.com/numpy/numpy/pull/11739</a></p>\n<p>This is exactly what happens in <a data-is-external-link=\"true\" href=\"#!/levitsky/pyteomics/src/decec05d63d7528342522a5ec2c9f1b22c41ffc3/pyteomics/xml.py?at=default#xml.py-161,162\" rel=\"nofollow\">line 161 &amp; 162 in <code>xml.py</code></a>. As a result, there is an error when trying to modify m/z and intensity arrays.</p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-04-08T22:57:36.170007+00:00", "milestone": null, "updated_on": "2019-04-25T14:58:06.167532+00:00", "type": "issue", "id": 38}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/39/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/39.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/39/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/39/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/39/bug-in-ms2-parser-_handle_s"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/39/vote"}}, "reporter": {"display_name": "Stephen Blaskowski", "uuid": "{3e968357-25d3-4cb4-966a-3c128545fa5d}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B3e968357-25d3-4cb4-966a-3c128545fa5d%7D"}, "html": {"href": "https://bitbucket.org/%7B3e968357-25d3-4cb4-966a-3c128545fa5d%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/59ccf9ccc7f8e3d2572987cd74bfd186d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSB-4.png"}}, "nickname": "blasks", "type": "user", "account_id": "5c82e24b03a1f86544381a3c"}, "title": "Bug in ms2 parser _handle_S", "component": null, "votes": 0, "watches": 1, "content": {"raw": "I was getting a key error when trying to parse an ms2 file. I made this change to my copy of the source code and it seemed to fix the problem\r\n\r\nIn MS1Base class:\r\n\r\n    def _handle_S(self, line, sline, params):\r\n        sline = line.strip().split(None, 3)\r\n        params['scan'] = tuple(sline[1:3])\r\n        if len(sline) == 4:  # in MS2 the S line contains the precursor m/z as a 4th column\r\n            params['precursor m/z'] = float(sline[3])    # change sline to params\r\n            # params['precursor m/z'] = float(params[3])    # original code", "markup": "markdown", "html": "<p>I was getting a key error when trying to parse an ms2 file. I made this change to my copy of the source code and it seemed to fix the problem</p>\n<p>In MS1Base class:</p>\n<div class=\"codehilite\"><pre><span></span>def _handle_S(self, line, sline, params):\n    sline = line.strip().split(None, 3)\n    params[&#39;scan&#39;] = tuple(sline[1:3])\n    if len(sline) == 4:  # in MS2 the S line contains the precursor m/z as a 4th column\n        params[&#39;precursor m/z&#39;] = float(sline[3])    # change sline to params\n        # params[&#39;precursor m/z&#39;] = float(params[3])    # original code\n</pre></div>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-04-23T19:23:37.155946+00:00", "milestone": null, "updated_on": "2019-04-25T14:30:31.154540+00:00", "type": "issue", "id": 39}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/40/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/40.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/40/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/40/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/40/std-bad_alloc-when-loading-multiple"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/40/vote"}}, "reporter": null, "title": "std::bad_alloc when loading multiple pyteomics submodules", "component": null, "votes": 0, "watches": null, "content": {"raw": "I'm having a strange error when I'm loading pyteomics biolccc and electrochem together. This only happens when I'm running a python script from the terminal, I have not had it when working in python.\r\n\r\nWhen I run the following script ('tester.py'):\r\n\r\nimport pyteomics.electrochem\r\nimport pyteomics.mass\r\nimport pyteomics.biolccc\r\n\r\nI get the following error:\r\n\r\nterminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\nAborted (core dumped)\r\n\r\nThe strange thing is this error only comes up around once out of every 10 times, so if I run:\r\n\r\nfor i in {1..10}; do python tester.py; done\r\n\r\nThen most of the times it will run fine. The one time that it does not work, I can see the memory (%MEM from top) slowly increasing until around 50%, and then I get the std::bad_alloc error message.\r\n\r\nI'm running Ubuntu Bionic Beaver, release 18.04. Any suggestions or ideas for why this might be occurring are greatly appreciated!", "markup": "markdown", "html": "<p>I'm having a strange error when I'm loading pyteomics biolccc and electrochem together. This only happens when I'm running a python script from the terminal, I have not had it when working in python.</p>\n<p>When I run the following script ('tester.py'):</p>\n<p>import pyteomics.electrochem\nimport pyteomics.mass\nimport pyteomics.biolccc</p>\n<p>I get the following error:</p>\n<p>terminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\nAborted (core dumped)</p>\n<p>The strange thing is this error only comes up around once out of every 10 times, so if I run:</p>\n<p>for i in {1..10}; do python tester.py; done</p>\n<p>Then most of the times it will run fine. The one time that it does not work, I can see the memory (%MEM from top) slowly increasing until around 50%, and then I get the std::bad_alloc error message.</p>\n<p>I'm running Ubuntu Bionic Beaver, release 18.04. Any suggestions or ideas for why this might be occurring are greatly appreciated!</p>", "type": "rendered"}, "assignee": null, "state": "open", "version": null, "edited_on": null, "created_on": "2019-05-28T20:33:36.046148+00:00", "milestone": null, "updated_on": "2019-08-09T22:39:14.193713+00:00", "type": "issue", "id": 40}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/41/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/41.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/41/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/41/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/41/mgf-files-containing-two-spectra-with-the"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/41/vote"}}, "reporter": null, "title": "mgf-files containing two spectra with the same title report only the second occurence", "component": null, "votes": 0, "watches": 1, "content": {"raw": "I have a mgf-file containing two spectra with the same title - but when reading them in ( (use_index=True as per default) only one is accessible. Problem is probably that the random access of a spectra is indexed by the title and that index stores a single entry of offsets. \r\n\r\nWould it be possible to have a list of offsets stored so that when iterating of spectra all spectra are reachable?\r\n\r\nIn non-indexed access both come through.", "markup": "markdown", "html": "<p>I have a mgf-file containing two spectra with the same title - but when reading them in ( (use_index=True as per default) only one is accessible. Problem is probably that the random access of a spectra is indexed by the title and that index stores a single entry of offsets. </p>\n<p>Would it be possible to have a list of offsets stored so that when iterating of spectra all spectra are reachable?</p>\n<p>In non-indexed access both come through.</p>", "type": "rendered"}, "assignee": null, "state": "closed", "version": null, "edited_on": null, "created_on": "2019-06-04T11:37:53.477744+00:00", "milestone": null, "updated_on": "2019-06-19T13:23:18.239247+00:00", "type": "issue", "id": 41}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/42/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/42.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/42/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/42/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/42/pyrrolysine-mass-is-incorrect"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/42/vote"}}, "reporter": {"display_name": "Lars Kolbowski", "uuid": "{fc1df402-e755-41a0-b5a6-d80421a2af72}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bfc1df402-e755-41a0-b5a6-d80421a2af72%7D"}, "html": {"href": "https://bitbucket.org/%7Bfc1df402-e755-41a0-b5a6-d80421a2af72%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5bc99e3bd64558662e6d627e/dab57bdc-7f90-48ff-9610-606fbf956a58/128"}}, "nickname": "Lars Kolbowski", "type": "user", "account_id": "5bc99e3bd64558662e6d627e"}, "title": "Pyrrolysine mass is incorrect", "component": null, "votes": 0, "watches": 1, "content": {"raw": "The mass in `std_aa_mass` for `O` is set to `255.15829`, which is the amino acid mass and not the residue mass. All other masses in this dict are aa residue masses.  \r\nThe composition in `std_aa_comp` is correct.\r\n\r\n`mass.calculate_mass(mass.std_aa_comp['O'])` returns `237.14772686285`", "markup": "markdown", "html": "<p>The mass in <code>std_aa_mass</code> for <code>O</code> is set to <code>255.15829</code>, which is the amino acid mass and not the residue mass. All other masses in this dict are aa residue masses.<br />\nThe composition in <code>std_aa_comp</code> is correct.</p>\n<p><code>mass.calculate_mass(mass.std_aa_comp['O'])</code> returns <code>237.14772686285</code></p>", "type": "rendered"}, "assignee": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-06-07T13:51:32.696005+00:00", "milestone": null, "updated_on": "2019-06-07T15:15:14.867447+00:00", "type": "issue", "id": 42}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/43/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/43.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/43/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/43/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/43/bug-tandemfilter-remove_decoy-option"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/43/vote"}}, "reporter": null, "title": "[bug] tandem.filter remove_decoy option", "component": null, "votes": 0, "watches": null, "content": {"raw": "Dear sir,\r\n\r\nWhen using the remove_decoy option in tandem.filter, I get more PSM hits back at a certain FDR level with\r\n\r\n```\r\n#!python\r\n\r\npyteomics.tandem.filter(xml, fdr=0.01, decoy_prefix = \"DECOY_\", **remove_decoy = True**)\r\n```\r\nthen with\r\n```\r\n#!python\r\n\r\npyteomics.tandem.filter(xml, fdr=0.01, decoy_prefix = \"DECOY_\", **remove_decoy = False**)\r\n```\r\n\r\n... which is unexpected. Is this a bug or something weird with my analysis?\r\n\r\nThanks,\r\nT.", "markup": "markdown", "html": "<p>Dear sir,</p>\n<p>When using the remove_decoy option in tandem.filter, I get more PSM hits back at a certain FDR level with</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">pyteomics</span><span class=\"o\">.</span><span class=\"n\">tandem</span><span class=\"o\">.</span><span class=\"n\">filter</span><span class=\"p\">(</span><span class=\"n\">xml</span><span class=\"p\">,</span> <span class=\"n\">fdr</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">decoy_prefix</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;DECOY_&quot;</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">remove_decoy</span> <span class=\"o\">=</span> <span class=\"bp\">True</span><span class=\"o\">**</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>then with</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"n\">pyteomics</span><span class=\"o\">.</span><span class=\"n\">tandem</span><span class=\"o\">.</span><span class=\"n\">filter</span><span class=\"p\">(</span><span class=\"n\">xml</span><span class=\"p\">,</span> <span class=\"n\">fdr</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">decoy_prefix</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;DECOY_&quot;</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">remove_decoy</span> <span class=\"o\">=</span> <span class=\"bp\">False</span><span class=\"o\">**</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>... which is unexpected. Is this a bug or something weird with my analysis?</p>\n<p>Thanks,\nT.</p>", "type": "rendered"}, "assignee": null, "state": "on hold", "version": null, "edited_on": null, "created_on": "2019-08-02T15:50:27.428713+00:00", "milestone": null, "updated_on": "2019-08-09T22:37:42.693836+00:00", "type": "issue", "id": 43}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/44/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/44.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/44/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/44/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/44/multiprocessing-queue-maxsize-too-large"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/44/vote"}}, "reporter": {"display_name": "Will Fondrie", "uuid": "{bd46207e-6e18-410d-8eb9-8e8b0cfc8048}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bbd46207e-6e18-410d-8eb9-8e8b0cfc8048%7D"}, "html": {"href": "https://bitbucket.org/%7Bbd46207e-6e18-410d-8eb9-8e8b0cfc8048%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/ef8b9dd3cbea3a9b5c9fb40afd0da5d0d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsWF-4.png"}}, "nickname": "wfondrie", "type": "user", "account_id": "557058:9a8caef5-c480-445b-8104-16aba2db1e8b"}, "title": "Multiprocessing Queue maxsize too large for MacOS", "component": null, "votes": 0, "watches": 1, "content": {"raw": "When attempting to use the `pyteomics.mzml.MzML.map()` method on MacOS, I ran into the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"read.py\", line 37, in <module>\r\n    x = test(\"test.mzML\")\r\n  File \"read.py\", line 28, in test\r\n    for f in mzml_data.map():\r\n  File \"/Users/wfondrie/anaconda3/lib/python3.7/site-packages/pyteomics/auxiliary/file_helpers.py\", line 1012, in map\r\n    in_queue = mp.Queue(int(1e7))\r\n  File \"/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/context.py\", line 102, in Queue\r\n    return Queue(maxsize, ctx=self.get_context())\r\n  File \"/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 48, in __init__\r\n    self._sem = ctx.BoundedSemaphore(maxsize)\r\n  File \"/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/context.py\", line 87, in BoundedSemaphore\r\n    return BoundedSemaphore(value, ctx=self.get_context())\r\n  File \"/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 145, in __init__\r\n    SemLock.__init__(self, SEMAPHORE, value, value, ctx=ctx)\r\n  File \"/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 59, in __init__\r\n    unlink_now)\r\nOSError: [Errno 22] Invalid argument\r\n```\r\n\r\nOn MacOS, it seems the maximum size for `mp.Queue()` is capped at 32767 \\(or 2^15 - 1, the largest 16-bit integer\\). What would be the effects of making the following change to `auxiliary/file_helpers.py`?\r\n\r\n```python\r\n# Current lines 1012 & 1013:\r\n        in_queue = mp.Queue(int(1e7))\r\n        out_queue = mp.Queue(int(1e7))\r\n\r\n# Proposed change:\r\n        in_queue = mp.Queue(32767)\r\n        out_queue = mp.Queue(32767)\r\n```", "markup": "markdown", "html": "<p>When attempting to use the <code>pyteomics.mzml.MzML.map()</code> method on MacOS, I ran into the following error:</p>\n<div class=\"codehilite\"><pre><span></span>Traceback (most recent call last):\n  File &quot;read.py&quot;, line 37, in &lt;module&gt;\n    x = test(&quot;test.mzML&quot;)\n  File &quot;read.py&quot;, line 28, in test\n    for f in mzml_data.map():\n  File &quot;/Users/wfondrie/anaconda3/lib/python3.7/site-packages/pyteomics/auxiliary/file_helpers.py&quot;, line 1012, in map\n    in_queue = mp.Queue(int(1e7))\n  File &quot;/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/context.py&quot;, line 102, in Queue\n    return Queue(maxsize, ctx=self.get_context())\n  File &quot;/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/queues.py&quot;, line 48, in __init__\n    self._sem = ctx.BoundedSemaphore(maxsize)\n  File &quot;/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/context.py&quot;, line 87, in BoundedSemaphore\n    return BoundedSemaphore(value, ctx=self.get_context())\n  File &quot;/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/synchronize.py&quot;, line 145, in __init__\n    SemLock.__init__(self, SEMAPHORE, value, value, ctx=ctx)\n  File &quot;/Users/wfondrie/anaconda3/lib/python3.7/multiprocessing/synchronize.py&quot;, line 59, in __init__\n    unlink_now)\nOSError: [Errno 22] Invalid argument\n</pre></div>\n\n\n<p>On MacOS, it seems the maximum size for <code>mp.Queue()</code> is capped at 32767 (or 2^15 - 1, the largest 16-bit integer). What would be the effects of making the following change to <code>auxiliary/file_helpers.py</code>?</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"c1\"># Current lines 1012 &amp; 1013:</span>\n        <span class=\"n\">in_queue</span> <span class=\"o\">=</span> <span class=\"n\">mp</span><span class=\"o\">.</span><span class=\"n\">Queue</span><span class=\"p\">(</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mf\">1e7</span><span class=\"p\">))</span>\n        <span class=\"n\">out_queue</span> <span class=\"o\">=</span> <span class=\"n\">mp</span><span class=\"o\">.</span><span class=\"n\">Queue</span><span class=\"p\">(</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mf\">1e7</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Proposed change:</span>\n        <span class=\"n\">in_queue</span> <span class=\"o\">=</span> <span class=\"n\">mp</span><span class=\"o\">.</span><span class=\"n\">Queue</span><span class=\"p\">(</span><span class=\"mi\">32767</span><span class=\"p\">)</span>\n        <span class=\"n\">out_queue</span> <span class=\"o\">=</span> <span class=\"n\">mp</span><span class=\"o\">.</span><span class=\"n\">Queue</span><span class=\"p\">(</span><span class=\"mi\">32767</span><span class=\"p\">)</span>\n</pre></div>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-08-18T21:08:04.002242+00:00", "milestone": null, "updated_on": "2019-11-30T20:16:25.398499+00:00", "type": "issue", "id": 44}, {"priority": "minor", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/45/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/45.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/45/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/45/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/45/pyteomics-cparserisoforms-module-feature"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/45/vote"}}, "reporter": {"display_name": "Carolina Rojas Ramirez", "uuid": "{da497e9e-eafd-4d28-a0fc-6cb8f16d0260}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bda497e9e-eafd-4d28-a0fc-6cb8f16d0260%7D"}, "html": {"href": "https://bitbucket.org/%7Bda497e9e-eafd-4d28-a0fc-6cb8f16d0260%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/f3a0aaa19bbaf653952441586f3f4b0ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCR-1.png"}}, "nickname": "MSChemicalGeek", "type": "user", "account_id": "5b71cbac6ae601076b7a1a12"}, "title": "Pyteomics cparser.isoforms module feature request", "component": null, "votes": 0, "watches": 1, "content": {"raw": "Hello, pyteomics Team!\r\n\r\nThanks first of all for your wonderful package, it is very helpful in my graduate school research. I use the \u201cisoforms\u201d method from the parser module all the time. Recently I have been in need of faster calculations, and I was wondering if in the near future a cython counterpart to the \u201cisoforms\u201d method could be created. \r\n\r\n\u200c\r\n\r\nBest wishes, \r\n\r\n\u200c\r\n\r\nCarolina", "markup": "markdown", "html": "<p>Hello, pyteomics Team!</p>\n<p>Thanks first of all for your wonderful package, it is very helpful in my graduate school research. I use the \u201cisoforms\u201d method from the parser module all the time. Recently I have been in need of faster calculations, and I was wondering if in the near future a cython counterpart to the \u201cisoforms\u201d method could be created. </p>\n<p>\u200c</p>\n<p>Best wishes, </p>\n<p>\u200c</p>\n<p>Carolina</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-08-27T20:19:02.763258+00:00", "milestone": null, "updated_on": "2019-10-22T14:30:43.057106+00:00", "type": "issue", "id": 45}, {"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/46/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/46.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/46/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/46/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/46/unit-primitives-and-cvstr-use-excessive"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/46/vote"}}, "reporter": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "title": "unit-primitives and cvstr use excessive memory", "component": null, "votes": 0, "watches": 1, "content": {"raw": "When I made the `unit`-primitives, I didn\u2019t think about memory consumption:\r\n\r\n```python\r\nfrom pyteomics.auxiliary.structures import unitfloat\r\nfrom pympler import asizeof\r\n\r\nx = unitfloat(50.0, \"m/z\")\r\nprint(asizeof.asizeof(x))\r\n# >>> 424\r\nprint(asizeof.asizeof(50.0))\r\n# >>> 24\r\nprint(asizeof.asizeof(\"m/z\"))\r\n# >>> 40\r\n```\r\n\r\nFortunately, this is pretty easy to fix, just slap `__slots__` on the types.\r\n\r\n```python\r\nclass lightunitfloat(float):\r\n    __slots__ = ('unit_info', )\r\n     def __new__(cls, value, unit_info=None):\r\n             inst = super(lightunitfloat, cls).__new__(cls, value)\r\n             inst.unit_info = unit_info\r\n     return inst\r\n\r\ny = lightunitfloat(50.0, \"m/z\")\r\nprint(asizeof.asizeof(y))\r\n# >>> 160\r\n```\r\n\r\nThis has the downside of making unpickling previously pickled instances break because the default unpickling logic assumes `__dict__`exists. We can solve that by adding:\r\n\r\n```python\r\nclass _MappingOverAttributeProxy(object):\r\n    '''A replacement for __dict__ for unpickling an object which once\r\n    has __slots__ now but did not before.'''\r\n\r\n    def __init__(self, obj):\r\n        self.obj = obj\r\n\r\n    def __getitem__(self, key):\r\n        return getattr(self.obj, key)\r\n\r\n    def __setitem__(self, key, value):\r\n        setattr(self.obj, key, value)\r\n\r\n    def __contains__(self, key):\r\n        return hasattr(self.obj, key)\r\n\r\n    def __repr__(self):\r\n        return \"{self.__class__.__name__}({self.obj})\".format(self=self)\r\n\r\nclass lightunitfloat(float):\r\n    __slots__ = ('unit_info', )\r\n    def __new__(cls, value, unit_info=None):\r\n        inst = super(lightunitfloat, cls).__new__(cls, value)\r\n        inst.unit_info = unit_info\r\n        return inst\r\n\r\n   def __reduce__(self):\r\n         return self.__class__, (float(self), self.unit_info)\r\n\r\n   @property\r\n   def __dict__(self):\r\n        return _MappingOverAttributeProxy(self)\r\n```\r\n\r\nI\u2019ll open a PR for this in the next few days.", "markup": "markdown", "html": "<p>When I made the <code>unit</code>-primitives, I didn\u2019t think about memory consumption:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">pyteomics.auxiliary.structures</span> <span class=\"kn\">import</span> <span class=\"n\">unitfloat</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pympler</span> <span class=\"kn\">import</span> <span class=\"n\">asizeof</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">unitfloat</span><span class=\"p\">(</span><span class=\"mf\">50.0</span><span class=\"p\">,</span> <span class=\"s2\">&quot;m/z&quot;</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">asizeof</span><span class=\"o\">.</span><span class=\"n\">asizeof</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n<span class=\"c1\"># &gt;&gt;&gt; 424</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">asizeof</span><span class=\"o\">.</span><span class=\"n\">asizeof</span><span class=\"p\">(</span><span class=\"mf\">50.0</span><span class=\"p\">))</span>\n<span class=\"c1\"># &gt;&gt;&gt; 24</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">asizeof</span><span class=\"o\">.</span><span class=\"n\">asizeof</span><span class=\"p\">(</span><span class=\"s2\">&quot;m/z&quot;</span><span class=\"p\">))</span>\n<span class=\"c1\"># &gt;&gt;&gt; 40</span>\n</pre></div>\n\n\n<p>Fortunately, this is pretty easy to fix, just slap <code>__slots__</code> on the types.</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">lightunitfloat</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">):</span>\n    <span class=\"vm\">__slots__</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">&#39;unit_info&#39;</span><span class=\"p\">,</span> <span class=\"p\">)</span>\n     <span class=\"k\">def</span> <span class=\"fm\">__new__</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">unit_info</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">):</span>\n             <span class=\"n\">inst</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">lightunitfloat</span><span class=\"p\">,</span> <span class=\"bp\">cls</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__new__</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n             <span class=\"n\">inst</span><span class=\"o\">.</span><span class=\"n\">unit_info</span> <span class=\"o\">=</span> <span class=\"n\">unit_info</span>\n     <span class=\"k\">return</span> <span class=\"n\">inst</span>\n\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">lightunitfloat</span><span class=\"p\">(</span><span class=\"mf\">50.0</span><span class=\"p\">,</span> <span class=\"s2\">&quot;m/z&quot;</span><span class=\"p\">)</span>\n<span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">asizeof</span><span class=\"o\">.</span><span class=\"n\">asizeof</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">))</span>\n<span class=\"c1\"># &gt;&gt;&gt; 160</span>\n</pre></div>\n\n\n<p>This has the downside of making unpickling previously pickled instances break because the default unpickling logic assumes <code>__dict__</code>exists. We can solve that by adding:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">_MappingOverAttributeProxy</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"sd\">&#39;&#39;&#39;A replacement for __dict__ for unpickling an object which once</span>\n<span class=\"sd\">    has __slots__ now but did not before.&#39;&#39;&#39;</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">obj</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">obj</span> <span class=\"o\">=</span> <span class=\"n\">obj</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__getitem__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"nb\">getattr</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">obj</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__setitem__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">):</span>\n        <span class=\"nb\">setattr</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">obj</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__contains__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">obj</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__repr__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"s2\">&quot;{self.__class__.__name__}({self.obj})&quot;</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">lightunitfloat</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">):</span>\n    <span class=\"vm\">__slots__</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">&#39;unit_info&#39;</span><span class=\"p\">,</span> <span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__new__</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">unit_info</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">):</span>\n        <span class=\"n\">inst</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">lightunitfloat</span><span class=\"p\">,</span> <span class=\"bp\">cls</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__new__</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n        <span class=\"n\">inst</span><span class=\"o\">.</span><span class=\"n\">unit_info</span> <span class=\"o\">=</span> <span class=\"n\">unit_info</span>\n        <span class=\"k\">return</span> <span class=\"n\">inst</span>\n\n   <span class=\"k\">def</span> <span class=\"nf\">__reduce__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n         <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"vm\">__class__</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">unit_info</span><span class=\"p\">)</span>\n\n   <span class=\"nd\">@property</span>\n   <span class=\"k\">def</span> <span class=\"nf\">__dict__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">_MappingOverAttributeProxy</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>I\u2019ll open a PR for this in the next few days.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-10-17T02:24:07.141398+00:00", "milestone": null, "updated_on": "2019-10-26T16:02:32.787837+00:00", "type": "issue", "id": 46}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/47/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/47.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/47/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/47/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/47/non-ascii-characters-in-auditcollection"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/47/vote"}}, "reporter": {"display_name": "Lutz Fischer", "uuid": "{7796ce7b-56d0-4b48-a5ee-2191230149f0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B7796ce7b-56d0-4b48-a5ee-2191230149f0%7D"}, "html": {"href": "https://bitbucket.org/%7B7796ce7b-56d0-4b48-a5ee-2191230149f0%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/5bc9ac295b8ba5286cb9d07d/f3ad5bf8-4343-4b38-bed9-3202f68f080d/128"}}, "nickname": "Lutz", "type": "user", "account_id": "5bc9ac295b8ba5286cb9d07d"}, "title": "non-ascii characters in AuditCollection lead to UnicodeEncodeError", "component": null, "votes": 0, "watches": 2, "content": {"raw": "Non-ascii charaters \\(like german umlaut `\u00e4` in `AuditCollection`  causes:\r\n\r\n\u200c\r\n\r\n```\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py\", line 1194, in next\r\n    return self.__next__()\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py\", line 1191, in __next__\r\n    return next(self._iterator)\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py\", line 571, in _iterfind_impl\r\n    info = self._get_info_smart(child, **kwargs)\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/mzid.py\", line 142, in _get_info_smart\r\n    **kwargs)\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py\", line 417, in _get_info\r\n    info[cname] = self._get_info_smart(child, ename=cname, **kwargs)\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/mzid.py\", line 142, in _get_info_smart\r\n    **kwargs)\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py\", line 413, in _get_info\r\n    newinfo = self._handle_param(child, **kwargs)\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py\", line 362, in _handle_param\r\n    value = unitstr(value, unit_info)\r\n  File \"/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/auxiliary/structures.py\", line 222, in __new__\r\n    inst = super(unitstr, cls).__new__(cls, value)\r\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\xe4' in position 7: ordinal not in range(128)\r\n```\r\n\r\n\u200c\r\n\r\nchanging  `pyteomics/auxiliary/structures.py:222` from\r\n\r\n```\r\nclass unitstr(str):\r\n    def __new__(cls, value, unit_info=None):\r\n        inst = super(unitstr, cls).__new__(cls, value)\r\n        inst.unit_info = unit_info\r\n        return inst\r\n```\r\n\r\nto\r\n\r\n\u200c\r\n\r\n```python\r\nclass unitstr(str):\r\n    def __new__(cls, value, unit_info=None):\r\n        inst = super(unitstr, cls).__new__(cls, value.encode('utf-8'))\r\n        inst.unit_info = unit_info\r\n        return inst\r\n```\r\n\r\nSeem to fix this issue.", "markup": "markdown", "html": "<p>Non-ascii charaters (like german umlaut <code>\u00e4</code> in <code>AuditCollection</code>  causes:</p>\n<p>\u200c</p>\n<div class=\"codehilite\"><pre><span></span>  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py&quot;, line 1194, in next\n    return self.__next__()\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py&quot;, line 1191, in __next__\n    return next(self._iterator)\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py&quot;, line 571, in _iterfind_impl\n    info = self._get_info_smart(child, **kwargs)\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/mzid.py&quot;, line 142, in _get_info_smart\n    **kwargs)\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py&quot;, line 417, in _get_info\n    info[cname] = self._get_info_smart(child, ename=cname, **kwargs)\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/mzid.py&quot;, line 142, in _get_info_smart\n    **kwargs)\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py&quot;, line 413, in _get_info\n    newinfo = self._handle_param(child, **kwargs)\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/xml.py&quot;, line 362, in _handle_param\n    value = unitstr(value, unit_info)\n  File &quot;/home/lfischer/.local/share/virtualenvs/pymzid-hkwy9F4K/local/lib/python2.7/site-packages/pyteomics/auxiliary/structures.py&quot;, line 222, in __new__\n    inst = super(unitstr, cls).__new__(cls, value)\nUnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode character u&#39;\\xe4&#39; in position 7: ordinal not in range(128)\n</pre></div>\n\n\n<p>\u200c</p>\n<p>changing  <code>pyteomics/auxiliary/structures.py:222</code> from</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kr\">class</span> <span class=\"nx\">unitstr</span><span class=\"p\">(</span><span class=\"nx\">str</span><span class=\"p\">)</span><span class=\"o\">:</span>\n    <span class=\"nx\">def</span> <span class=\"nx\">__new__</span><span class=\"p\">(</span><span class=\"nx\">cls</span><span class=\"p\">,</span> <span class=\"nx\">value</span><span class=\"p\">,</span> <span class=\"nx\">unit_info</span><span class=\"o\">=</span><span class=\"nx\">None</span><span class=\"p\">)</span><span class=\"o\">:</span>\n        <span class=\"nx\">inst</span> <span class=\"o\">=</span> <span class=\"kr\">super</span><span class=\"p\">(</span><span class=\"nx\">unitstr</span><span class=\"p\">,</span> <span class=\"nx\">cls</span><span class=\"p\">).</span><span class=\"nx\">__new__</span><span class=\"p\">(</span><span class=\"nx\">cls</span><span class=\"p\">,</span> <span class=\"nx\">value</span><span class=\"p\">)</span>\n        <span class=\"nx\">inst</span><span class=\"p\">.</span><span class=\"nx\">unit_info</span> <span class=\"o\">=</span> <span class=\"nx\">unit_info</span>\n        <span class=\"k\">return</span> <span class=\"nx\">inst</span>\n</pre></div>\n\n\n<p>to</p>\n<p>\u200c</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">unitstr</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__new__</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">unit_info</span><span class=\"o\">=</span><span class=\"bp\">None</span><span class=\"p\">):</span>\n        <span class=\"n\">inst</span> <span class=\"o\">=</span> <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">unitstr</span><span class=\"p\">,</span> <span class=\"bp\">cls</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__new__</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s1\">&#39;utf-8&#39;</span><span class=\"p\">))</span>\n        <span class=\"n\">inst</span><span class=\"o\">.</span><span class=\"n\">unit_info</span> <span class=\"o\">=</span> <span class=\"n\">unit_info</span>\n        <span class=\"k\">return</span> <span class=\"n\">inst</span>\n</pre></div>\n\n\n<p>Seem to fix this issue.</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-10-22T08:22:16.441047+00:00", "milestone": null, "updated_on": "2019-11-30T19:49:21.022797+00:00", "type": "issue", "id": 47}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/48/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/48.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/48/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/48/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/48/pepxmldataframe-error"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/48/vote"}}, "reporter": null, "title": "pepxml.DataFrame error", "component": null, "votes": 0, "watches": null, "content": {"raw": "Hi,\r\nI was trying to read a .pep.xml file by DataFrame, but I constantly got the same error.\r\n\r\nMy code:\r\n\r\n```\r\n#!python\r\n...\r\na=pepxml.read(\"interact.pep.xml\")\r\nb=pepxml.DataFrame(a)\r\n...\r\n```\r\n\r\nError:\r\n\r\n\r\n```\r\n#!\r\n\r\nTraceback (most recent call last):\r\n  File \"InteractPepXMLParser.py\", line 20, in <module>\r\n    b=pepxml.DataFrame(a)\r\n  File \"C:\\Users\\Armin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pyteomics\\pepxml.py\", line 412, in DataFrame\r\n    return pd.DataFrame(gen_items(), **pd_kwargs)\r\n  File \"C:\\Users\\Armin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\core\\frame.py\", line 382, in __init__\r\n    data = list(data)\r\n  File \"C:\\Users\\Armin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pyteomics\\pepxml.py\", line 406, in gen_items\r\n    info.update(ar['peptideprophet_result']['parameter'])\r\nKeyError: 'parameter'\r\n```\r\n\r\n\r\nThis happened after I changed some of my PeptideProphet settings. (The function works fine for some sort of settings.) I should mention that pepxml.filter works fine in every situation.\r\nCould you please help me?", "markup": "markdown", "html": "<p>Hi,\nI was trying to read a .pep.xml file by DataFrame, but I constantly got the same error.</p>\n<p>My code:</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"o\">...</span>\n<span class=\"n\">a</span><span class=\"o\">=</span><span class=\"n\">pepxml</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"s2\">&quot;interact.pep.xml&quot;</span><span class=\"p\">)</span>\n<span class=\"n\">b</span><span class=\"o\">=</span><span class=\"n\">pepxml</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n</pre></div>\n\n\n<p>Error:</p>\n<div class=\"codehilite\"><pre><span></span>Traceback (most recent call last):\n  File &quot;InteractPepXMLParser.py&quot;, line 20, in &lt;module&gt;\n    b=pepxml.DataFrame(a)\n  File &quot;C:\\Users\\Armin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pyteomics\\pepxml.py&quot;, line 412, in DataFrame\n    return pd.DataFrame(gen_items(), **pd_kwargs)\n  File &quot;C:\\Users\\Armin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\core\\frame.py&quot;, line 382, in __init__\n    data = list(data)\n  File &quot;C:\\Users\\Armin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pyteomics\\pepxml.py&quot;, line 406, in gen_items\n    info.update(ar[&#39;peptideprophet_result&#39;][&#39;parameter&#39;])\nKeyError: &#39;parameter&#39;\n</pre></div>\n\n\n<p>This happened after I changed some of my PeptideProphet settings. (The function works fine for some sort of settings.) I should mention that pepxml.filter works fine in every situation.\nCould you please help me?</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-10-26T21:53:35.370497+00:00", "milestone": null, "updated_on": "2019-10-27T16:15:53.762988+00:00", "type": "issue", "id": 48}, {"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/levitsky/pyteomics.json"}, "html": {"href": "#!/levitsky/pyteomics"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3f6302de-10da-4d3c-b258-0bb6a2368972}ts=74456"}}, "type": "repository", "name": "pyteomics", "full_name": "levitsky/pyteomics", "uuid": "{3f6302de-10da-4d3c-b258-0bb6a2368972}"}, "links": {"attachments": {"href": "data/repositories/levitsky/pyteomics/issues/49/attachments_page=1.json"}, "self": {"href": "data/repositories/levitsky/pyteomics/issues/49.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/49/watch"}, "comments": {"href": "data/repositories/levitsky/pyteomics/issues/49/comments_page=1.json"}, "html": {"href": "#!/levitsky/pyteomics/issues/49/mzidentml-wrong-annotation-in-dataframe"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/levitsky/pyteomics/issues/49/vote"}}, "reporter": null, "title": "mzidentml wrong annotation in DataFrame", "component": null, "votes": 0, "watches": null, "content": {"raw": "Hi Lev: \r\n\r\nI was using the pyteomics library for our spectra library project. I notice when reading an mzidentml into a Dataframe that the isDecoy field for all the PSMs is False. Do you filter the decoy PSMs?", "markup": "markdown", "html": "<p>Hi Lev: </p>\n<p>I was using the pyteomics library for our spectra library project. I notice when reading an mzidentml into a Dataframe that the isDecoy field for all the PSMs is False. Do you filter the decoy PSMs?</p>", "type": "rendered"}, "assignee": null, "state": "on hold", "version": null, "edited_on": null, "created_on": "2020-01-21T13:43:43.559356+00:00", "milestone": null, "updated_on": "2020-02-18T16:23:47.698625+00:00", "type": "issue", "id": 49}], "page": 1, "size": 49}