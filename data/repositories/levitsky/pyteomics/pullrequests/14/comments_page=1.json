{"pagelen": 100, "values": [{"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/53031102.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-53031102"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "I was planning to do more with this, but it was better to get the basic functionality out and up for review before going too far.\n\nThis essentially lets us only pay for decoding the binary arrays if we want to access the array data. It does cost a bit of abstraction, rather than providing a transparent view of the file contents with no middle-man it introduces a class that essentially tries to negotiate only one point of access with the consumer of the scan data, rather than all points of access. Of course, you only pay for it if you opt to not decode in the first place, and don't need to interact with the namedtuple if it's not important to you to decode it later.\n\nI also started stubbing in logic for more compression methods. We know there is Numpress and in the past year CV terms were added for layered compression methods. The BinaryDataArrayTransformer can have new decompression methods registered at run time without needing to make them built into Pyteomics.\n\n\n", "markup": "markdown", "html": "<p>I was planning to do more with this, but it was better to get the basic functionality out and up for review before going too far.</p>\n<p>This essentially lets us only pay for decoding the binary arrays if we want to access the array data. It does cost a bit of abstraction, rather than providing a transparent view of the file contents with no middle-man it introduces a class that essentially tries to negotiate only one point of access with the consumer of the scan data, rather than all points of access. Of course, you only pay for it if you opt to not decode in the first place, and don't need to interact with the namedtuple if it's not important to you to decode it later.</p>\n<p>I also started stubbing in logic for more compression methods. We know there is Numpress and in the past year CV terms were added for layered compression methods. The BinaryDataArrayTransformer can have new decompression methods registered at run time without needing to make them built into Pyteomics.</p>", "type": "rendered"}, "created_on": "2018-01-05T02:01:48.839970+00:00", "user": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "updated_on": "2018-01-05T02:01:49.042823+00:00", "type": "pullrequest_comment", "id": 53031102}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/53093075.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-53093075"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "Thank you.\n\nI have no objections with regard to logic or implementation.\n\nDealing almost exclusively with Proteowizard-generated mzML (and MGF), and using mostly the array data in them, I don't have an exact idea of the use cases this is aimed at, but I believe there are many.\nWhat else did you want to do on this? Do you want it merged now or would you prefer to add something?\n\nI see that since the encoded strings in mzXML contain pairs, the undecoded records in the output are duplicated under 'intensity array' and 'm/z array' keys. When decode() is called on those, we get the full compound array.\nCan we maybe make it behave more like mzML? I'm thinking, maybe we could also save the key in the record object and only retrieve the corresponding part of the data on decode().\nIf you don't think that's a good idea, maybe we should at least avoid the duplication and plug in the reference to the same object under both keys.", "markup": "markdown", "html": "<p>Thank you.</p>\n<p>I have no objections with regard to logic or implementation.</p>\n<p>Dealing almost exclusively with Proteowizard-generated mzML (and MGF), and using mostly the array data in them, I don't have an exact idea of the use cases this is aimed at, but I believe there are many.\nWhat else did you want to do on this? Do you want it merged now or would you prefer to add something?</p>\n<p>I see that since the encoded strings in mzXML contain pairs, the undecoded records in the output are duplicated under 'intensity array' and 'm/z array' keys. When decode() is called on those, we get the full compound array.\nCan we maybe make it behave more like mzML? I'm thinking, maybe we could also save the key in the record object and only retrieve the corresponding part of the data on decode().\nIf you don't think that's a good idea, maybe we should at least avoid the duplication and plug in the reference to the same object under both keys.</p>", "type": "rendered"}, "created_on": "2018-01-05T18:39:52.881752+00:00", "user": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "updated_on": "2018-01-05T18:39:52.884095+00:00", "type": "pullrequest_comment", "id": 53093075}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/53102252.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-53102252"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "I did try a callback-based design for mzXML, but the behavior felt clumsy. Something less clumsy would be to have the MzXML class override `binary_array_record` to be a new namedtuple doing just what you described. I'll implement that.\n\nI had some ideas about indexing compressed files, but my research has found that that can't be done unless the file is compressed using a more sophisticated compressor (https://github.com/mobiusklein/python-idzip). This is like, but not the same as BGZF. In theory, bzip2 should work for this purpose as well, but the Python implementation, hidden inside the _bz2 extension module, uses the same linear decompression for seeking that the gzip module does. ", "markup": "markdown", "html": "<p>I did try a callback-based design for mzXML, but the behavior felt clumsy. Something less clumsy would be to have the MzXML class override <code>binary_array_record</code> to be a new namedtuple doing just what you described. I'll implement that.</p>\n<p>I had some ideas about indexing compressed files, but my research has found that that can't be done unless the file is compressed using a more sophisticated compressor (<a href=\"https://github.com/mobiusklein/python-idzip\" rel=\"nofollow\" class=\"ap-connect-link\">https://github.com/mobiusklein/python-idzip</a>). This is like, but not the same as BGZF. In theory, bzip2 should work for this purpose as well, but the Python implementation, hidden inside the _bz2 extension module, uses the same linear decompression for seeking that the gzip module does. </p>", "type": "rendered"}, "created_on": "2018-01-05T21:31:08.121928+00:00", "user": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "updated_on": "2018-01-05T21:31:08.200956+00:00", "type": "pullrequest_comment", "id": 53102252}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/53721736.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-53721736"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "I've made the change to `binary_array_record` so that the behavior will match between `MzML` and `MzXML`, and updated the tests.", "markup": "markdown", "html": "<p>I've made the change to <code>binary_array_record</code> so that the behavior will match between <code>MzML</code> and <code>MzXML</code>, and updated the tests.</p>", "type": "rendered"}, "created_on": "2018-01-15T19:48:14.989587+00:00", "user": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "updated_on": "2018-01-15T19:48:15.052027+00:00", "type": "pullrequest_comment", "id": 53721736}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/53730677.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-53730677"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "Awesome!\n\nOne nit I see now is that the `ArrayConversionMixin` doesn't do its thing when decoding is deferred (`_convert_array` is only called with `decode_binary=True`). What I feel the user would expect is that `dtype` argument is compatible with `decode_binary=False`. Since it makes sense to do the conversion after the record's `decode()` is called, it looks like it's hard to do by overriding methods of `ArrayConversionMixin` and easier to do by subclassing `binary_array_record`.\nThe sanest way I was able to do that is like this:\n\n```\n#!diff\n\n\ndiff -r c224aee7ccf4 pyteomics/auxiliary.py\n--- a/pyteomics/auxiliary.py    Mon Jan 15 14:44:36 2018 -0500\n+++ b/pyteomics/auxiliary.py    Tue Jan 16 01:24:18 2018 +0300\n@@ -1435,6 +1435,23 @@\n     output = np.frombuffer(decoded_source, dtype=dtype)\n     return output\n \n+class binary_array_record(namedtuple(\n+    \"binary_array_record\", (\"data\", \"compression\", \"dtype\", \"source\", \"key\"))):\n+    \"\"\"Hold all of the information about a base64 encoded array needed to\n+    decode the array.\n+    \"\"\"\n+\n+    def decode(self):\n+        \"\"\"Decode :attr:`data` into a numerical array\n+\n+        Returns\n+        -------\n+        np.ndarray\n+        \"\"\"\n+        if self.key is None:\n+            return self.source._decode_record(self)\n+        else:\n+            return self.source._decode_record(self)[self.key]\n \n class BinaryDataArrayTransformer(object):\n     \"\"\"A base class that provides methods for reading\n@@ -1451,23 +1468,7 @@\n         'zlib compression': zlib.decompress,\n     }\n \n-    class binary_array_record(namedtuple(\n-        \"binary_array_record\", (\"data\", \"compression\", \"dtype\", \"source\", \"key\"))):\n-        \"\"\"Hold all of the information about a base64 encoded array needed to\n-        decode the array.\n-        \"\"\"\n-\n-        def decode(self):\n-            \"\"\"Decode :attr:`data` into a numerical array\n-\n-            Returns\n-            -------\n-            np.ndarray\n-            \"\"\"\n-            if self.key is None:\n-                return self.source._decode_record(self)\n-            else:\n-                return self.source._decode_record(self)[self.key]\n+    binary_array_record = binary_array_record\n \n     def _make_record(self, data, compression, dtype, key=None):\n         return self.binary_array_record(data, compression, dtype, self, key)\ndiff -r c224aee7ccf4 pyteomics/xml.py\n--- a/pyteomics/xml.py  Mon Jan 15 14:44:36 2018 -0500\n+++ b/pyteomics/xml.py  Tue Jan 16 01:24:18 2018 +0300\n@@ -42,7 +42,7 @@\n from .auxiliary import FileReader, PyteomicsError, basestring, _file_obj\n from .auxiliary import unitint, unitfloat, unitstr\n from .auxiliary import _keepstate_method as _keepstate\n-from .auxiliary import BinaryDataArrayTransformer\n+from .auxiliary import BinaryDataArrayTransformer, binary_array_record\n try: # Python 2.7\n     from urllib2 import urlopen, URLError\n except ImportError: # Python 3.x\n@@ -1079,9 +1079,15 @@\n         with cls(path, use_index=True) as inst:\n             inst.write_byte_offsets()\n \n+class converting_binary_array_record(binary_array_record):\n+    def decode(self):\n+        decoded = super(converting_binary_array_record, self).decode()\n+        return self.source._convert_array(self.key, decoded)\n+\n class ArrayConversionMixin(BinaryDataArrayTransformer):\n     _dtype_dict = {}\n     _array_keys = ['m/z array', 'intensity array']\n+    binary_array_record = converting_binary_array_record\n \n     def __init__(self, *args, **kwargs):\n         self._dtype_dict.setdefault(None, None)\n@@ -1099,6 +1105,8 @@\n             return array.astype(dtype)\n         return array\n \n+    \n+\n _trafoxml_schema_defaults = {'bools': set(),\n      'charlists': set(),\n      'floatlists': set(),\n```\n\nDoes it make sense to you? Is there a better way?", "markup": "markdown", "html": "<p>Awesome!</p>\n<p>One nit I see now is that the <code>ArrayConversionMixin</code> doesn't do its thing when decoding is deferred (<code>_convert_array</code> is only called with <code>decode_binary=True</code>). What I feel the user would expect is that <code>dtype</code> argument is compatible with <code>decode_binary=False</code>. Since it makes sense to do the conversion after the record's <code>decode()</code> is called, it looks like it's hard to do by overriding methods of <code>ArrayConversionMixin</code> and easier to do by subclassing <code>binary_array_record</code>.\nThe sanest way I was able to do that is like this:</p>\n<div class=\"codehilite language-diff\"><pre><span></span><span class=\"gh\">diff -r c224aee7ccf4 pyteomics/auxiliary.py</span>\n<span class=\"gd\">--- a/pyteomics/auxiliary.py    Mon Jan 15 14:44:36 2018 -0500</span>\n<span class=\"gi\">+++ b/pyteomics/auxiliary.py    Tue Jan 16 01:24:18 2018 +0300</span>\n<span class=\"gu\">@@ -1435,6 +1435,23 @@</span>\n     output = np.frombuffer(decoded_source, dtype=dtype)\n     return output\n\n<span class=\"gi\">+class binary_array_record(namedtuple(</span>\n<span class=\"gi\">+    &quot;binary_array_record&quot;, (&quot;data&quot;, &quot;compression&quot;, &quot;dtype&quot;, &quot;source&quot;, &quot;key&quot;))):</span>\n<span class=\"gi\">+    &quot;&quot;&quot;Hold all of the information about a base64 encoded array needed to</span>\n<span class=\"gi\">+    decode the array.</span>\n<span class=\"gi\">+    &quot;&quot;&quot;</span>\n<span class=\"gi\">+</span>\n<span class=\"gi\">+    def decode(self):</span>\n<span class=\"gi\">+        &quot;&quot;&quot;Decode :attr:`data` into a numerical array</span>\n<span class=\"gi\">+</span>\n<span class=\"gi\">+        Returns</span>\n<span class=\"gi\">+        -------</span>\n<span class=\"gi\">+        np.ndarray</span>\n<span class=\"gi\">+        &quot;&quot;&quot;</span>\n<span class=\"gi\">+        if self.key is None:</span>\n<span class=\"gi\">+            return self.source._decode_record(self)</span>\n<span class=\"gi\">+        else:</span>\n<span class=\"gi\">+            return self.source._decode_record(self)[self.key]</span>\n\n class BinaryDataArrayTransformer(object):\n     &quot;&quot;&quot;A base class that provides methods for reading\n<span class=\"gu\">@@ -1451,23 +1468,7 @@</span>\n         &#39;zlib compression&#39;: zlib.decompress,\n     }\n\n<span class=\"gd\">-    class binary_array_record(namedtuple(</span>\n<span class=\"gd\">-        &quot;binary_array_record&quot;, (&quot;data&quot;, &quot;compression&quot;, &quot;dtype&quot;, &quot;source&quot;, &quot;key&quot;))):</span>\n<span class=\"gd\">-        &quot;&quot;&quot;Hold all of the information about a base64 encoded array needed to</span>\n<span class=\"gd\">-        decode the array.</span>\n<span class=\"gd\">-        &quot;&quot;&quot;</span>\n<span class=\"gd\">-</span>\n<span class=\"gd\">-        def decode(self):</span>\n<span class=\"gd\">-            &quot;&quot;&quot;Decode :attr:`data` into a numerical array</span>\n<span class=\"gd\">-</span>\n<span class=\"gd\">-            Returns</span>\n<span class=\"gd\">-            -------</span>\n<span class=\"gd\">-            np.ndarray</span>\n<span class=\"gd\">-            &quot;&quot;&quot;</span>\n<span class=\"gd\">-            if self.key is None:</span>\n<span class=\"gd\">-                return self.source._decode_record(self)</span>\n<span class=\"gd\">-            else:</span>\n<span class=\"gd\">-                return self.source._decode_record(self)[self.key]</span>\n<span class=\"gi\">+    binary_array_record = binary_array_record</span>\n\n     def _make_record(self, data, compression, dtype, key=None):\n         return self.binary_array_record(data, compression, dtype, self, key)\n<span class=\"gh\">diff -r c224aee7ccf4 pyteomics/xml.py</span>\n<span class=\"gd\">--- a/pyteomics/xml.py  Mon Jan 15 14:44:36 2018 -0500</span>\n<span class=\"gi\">+++ b/pyteomics/xml.py  Tue Jan 16 01:24:18 2018 +0300</span>\n<span class=\"gu\">@@ -42,7 +42,7 @@</span>\n from .auxiliary import FileReader, PyteomicsError, basestring, _file_obj\n from .auxiliary import unitint, unitfloat, unitstr\n from .auxiliary import _keepstate_method as _keepstate\n<span class=\"gd\">-from .auxiliary import BinaryDataArrayTransformer</span>\n<span class=\"gi\">+from .auxiliary import BinaryDataArrayTransformer, binary_array_record</span>\n try: # Python 2.7\n     from urllib2 import urlopen, URLError\n except ImportError: # Python 3.x\n<span class=\"gu\">@@ -1079,9 +1079,15 @@</span>\n         with cls(path, use_index=True) as inst:\n             inst.write_byte_offsets()\n\n<span class=\"gi\">+class converting_binary_array_record(binary_array_record):</span>\n<span class=\"gi\">+    def decode(self):</span>\n<span class=\"gi\">+        decoded = super(converting_binary_array_record, self).decode()</span>\n<span class=\"gi\">+        return self.source._convert_array(self.key, decoded)</span>\n<span class=\"gi\">+</span>\n class ArrayConversionMixin(BinaryDataArrayTransformer):\n     _dtype_dict = {}\n     _array_keys = [&#39;m/z array&#39;, &#39;intensity array&#39;]\n<span class=\"gi\">+    binary_array_record = converting_binary_array_record</span>\n\n     def __init__(self, *args, **kwargs):\n         self._dtype_dict.setdefault(None, None)\n<span class=\"gu\">@@ -1099,6 +1105,8 @@</span>\n             return array.astype(dtype)\n         return array\n\n<span class=\"gi\">+    </span>\n<span class=\"gi\">+</span>\n _trafoxml_schema_defaults = {&#39;bools&#39;: set(),\n      &#39;charlists&#39;: set(),\n      &#39;floatlists&#39;: set(),\n</pre></div>\n\n\n<p>Does it make sense to you? Is there a better way?</p>", "type": "rendered"}, "created_on": "2018-01-15T22:26:10.607148+00:00", "user": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "updated_on": "2018-01-15T22:26:10.609142+00:00", "type": "pullrequest_comment", "id": 53730677}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/53950253.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-53950253"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "I think a better solution is to accept that records are not synonymous with the arrays they encode much earlier in the abstraction, and to push the logic that completes the conversion from record to array up the class hierarchy. Then we can associate keys with arrays in both mzML and mzXML without breaking how they are unpacked, as this would have to in order to properly encode things.\n\nWe already have the `binary_array_record.decode` method calling `BinaryDataArrayTransformer._decode_record` which begins the process, and is currently just a wrapper around `decode_data_array` with the unpacked record. We could either repeatedly overload this method every time we want to add more processing to it (leading to lots of super calls) or we can decompose it into multiple methods, some of which are no-ops on the base classes. Since the most abstract forms are never used directly, \n\n```python\nclass BinaryDataArrayTransformer(object):\n    ...\n    def _decode_record(self, record):\n        array = self.decode_data_array(\n            record.data, record.compression, record.dtype)\n        return self._finalize_record_conversion(array, record)\n\n    def _finalize_record_conversion(self, array, record):\n        return array\n```\nInstead of overriding `_decode_record` directly and calling super() inside, we override one\nstep inside and use it to inject a call to `_convert_array` on the record.\n```python\nclass ArrayConversionMixin(BinaryDataArrayTransformer):\n    ...\n    def _finalize_record_conversion(self, array, record):\n        key = record.key\n        return self._convert_array(key, array)\n```\nThen instead of needing to call super() and find another way to encode how to unpack the compound array in mzXML files, we can do it in one pass here again with one method override.\n```python\nclass MzXML(xml.ArrayConversionMixin, xml.IndexSavingXML):\n    ...\n    def _finalize_record_conversion(self, array, record):\n        key = record.key\n        return self._convert_array(key, array[key])\n```\nIf this process were a bit more complex than injecting a single method call though, using super would probably be less work to maintain in the future, but it's hard to see that happening. The newer binary formats like mz5, mzdb and mzmlb retain the distinct binary blobs for each array.", "markup": "markdown", "html": "<p>I think a better solution is to accept that records are not synonymous with the arrays they encode much earlier in the abstraction, and to push the logic that completes the conversion from record to array up the class hierarchy. Then we can associate keys with arrays in both mzML and mzXML without breaking how they are unpacked, as this would have to in order to properly encode things.</p>\n<p>We already have the <code>binary_array_record.decode</code> method calling <code>BinaryDataArrayTransformer._decode_record</code> which begins the process, and is currently just a wrapper around <code>decode_data_array</code> with the unpacked record. We could either repeatedly overload this method every time we want to add more processing to it (leading to lots of super calls) or we can decompose it into multiple methods, some of which are no-ops on the base classes. Since the most abstract forms are never used directly, </p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">BinaryDataArrayTransformer</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_decode_record</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">):</span>\n        <span class=\"n\">array</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decode_data_array</span><span class=\"p\">(</span>\n            <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">compression</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_finalize_record_conversion</span><span class=\"p\">(</span><span class=\"n\">array</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">_finalize_record_conversion</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">array</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"n\">array</span>\n</pre></div>\n\n\n<p>Instead of overriding <code>_decode_record</code> directly and calling super() inside, we override one\nstep inside and use it to inject a call to <code>_convert_array</code> on the record.</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">ArrayConversionMixin</span><span class=\"p\">(</span><span class=\"n\">BinaryDataArrayTransformer</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_finalize_record_conversion</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">array</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">):</span>\n        <span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">key</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_convert_array</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">array</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>Then instead of needing to call super() and find another way to encode how to unpack the compound array in mzXML files, we can do it in one pass here again with one method override.</p>\n<div class=\"codehilite language-python\"><pre><span></span><span class=\"k\">class</span> <span class=\"nc\">MzXML</span><span class=\"p\">(</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">ArrayConversionMixin</span><span class=\"p\">,</span> <span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">IndexSavingXML</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_finalize_record_conversion</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">array</span><span class=\"p\">,</span> <span class=\"n\">record</span><span class=\"p\">):</span>\n        <span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">key</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_convert_array</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">array</span><span class=\"p\">[</span><span class=\"n\">key</span><span class=\"p\">])</span>\n</pre></div>\n\n\n<p>If this process were a bit more complex than injecting a single method call though, using super would probably be less work to maintain in the future, but it's hard to see that happening. The newer binary formats like mz5, mzdb and mzmlb retain the distinct binary blobs for each array.</p>", "type": "rendered"}, "created_on": "2018-01-17T19:47:29.860772+00:00", "user": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "updated_on": "2018-01-17T19:47:30.001497+00:00", "type": "pullrequest_comment", "id": 53950253}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/54532356.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-54532356"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "This certainly works, thanks! Should I merge now?", "markup": "markdown", "html": "<p>This certainly works, thanks! Should I merge now?</p>", "type": "rendered"}, "created_on": "2018-01-24T17:22:07.903406+00:00", "user": {"display_name": "Lev Levitsky", "uuid": "{eb44325f-4ee0-4e0b-a27c-f2ea23122a56}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D"}, "html": {"href": "https://bitbucket.org/%7Beb44325f-4ee0-4e0b-a27c-f2ea23122a56%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/a2593c44c42429c503d2e5e9e307e241d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsLL-6.png"}}, "nickname": "levitsky", "type": "user", "account_id": "557058:986c547b-c50a-40b3-948a-29b4a93b7b30"}, "updated_on": "2018-01-24T17:22:07.905155+00:00", "type": "pullrequest_comment", "id": 54532356}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/54532423.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-54532423"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "Sure.", "markup": "markdown", "html": "<p>Sure.</p>", "type": "rendered"}, "created_on": "2018-01-24T17:22:49.027263+00:00", "user": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "updated_on": "2018-01-24T17:22:49.052447+00:00", "type": "pullrequest_comment", "id": 54532423}, {"links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14/comments/54533682.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14/_/diff#comment-54533682"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 14, "links": {"self": {"href": "data/repositories/levitsky/pyteomics/pullrequests/14.json"}, "html": {"href": "#!/levitsky/pyteomics/pull-requests/14"}}, "title": "Compression factoring"}, "content": {"raw": "Thank you", "markup": "markdown", "html": "<p>Thank you</p>", "type": "rendered"}, "created_on": "2018-01-24T17:35:16.570158+00:00", "user": {"display_name": "Joshua Klein", "uuid": "{919f0add-304d-4b9a-8889-d2622a3dbc96}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D"}, "html": {"href": "https://bitbucket.org/%7B919f0add-304d-4b9a-8889-d2622a3dbc96%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/7d0e70bc74f783efa621a2bdd228ca22d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJK-3.png"}}, "nickname": "mobiusklein", "type": "user", "account_id": "557058:ff82222f-afe5-4135-a1b7-8de99a00f669"}, "updated_on": "2018-01-24T17:35:16.598765+00:00", "type": "pullrequest_comment", "id": 54533682}], "page": 1, "size": 9}